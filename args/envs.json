{
"comment__": "These environments come from the PLAiD work",
"PD_Biped2D_Flat_Terrain-v0": 
{
	"config_file": "./args/genBiped2D/biped2dfull_flat_with_terrain_features.txt",
	"time_limit": 256
},
"PD_Biped2D_Incline_Terrain-v0": 
{
	"config_file": "./args/genBiped2D/biped2dfull_incline_with_terrain_features.txt",
	"time_limit": 256,
	"TerrainRL_Parameters":
    {	
    		"comment__": "Use simple DeepLoco HLC reward function",
    	"render_mode": "3d"
    }
},
"PD_Biped2D_Steps_Terrain-v0": 
{
	"config_file": "./args/genBiped2D/biped2d_full_steps.txt",
	"time_limit": 256
},
"PD_Biped2D_Slopes_Terrain-v0": 
{
	"config_file": "./args/genBiped2D/biped2d_full_slopes_with_terrain_features.txt",
	"time_limit": 256
},
"PD_Biped2D_Gaps_Terrain-v0": 
{
	"config_file": "./args/genBiped2D/biped2d_full_gaps_with_terrain_features.txt",
	"time_limit": 256,
	"TerrainRL_Parameters":
    {	
    		"comment__": "Use simple DeepLoco HLC reward function",
    	"render_mode": "3d"
    }
},
"PD_Biped2D_Cliff_v0": 
{
	"config_file": "./args/genBiped2D/biped2d_full_cliff.txt",
	"time_limit": 256,
	"TerrainRL_Parameters":
    {	
    		"comment__": "Specific controller type to use",
    	"char_ctrl": "ct_pd",
    	"InitialPaddingWidth": "0.7"
    },
    	"comment__": "Key Presses that change some of the rendered parts of the simulation",
    "rendering_key_presses": ["c", "k", "j"]
	
},
"PD_Biped2D_Pedistal_v1": 
{
	"config_file": "./args/genBiped2D/biped2d_full_cliff.txt",
	"time_limit": 256,
	"TerrainRL_Parameters":
    {	
    	"scenario": "sim_char",
    		"comment__": "Specific controller type to use",
    	"char_ctrl": "ct_pd",
    		"comment__": "Use simple DeepLoco HLC reward function",
    	"terrain_file": "data/terrain/cliff_humanoid2.txt",
    		"comment__": "Use a different state file",
    	"state_file": "data/states/biped2D_full_stand_state.txt",
    		"comment__": "Randomly add forces to the links of the agent",
    	"enable_rand_perturbs": "true",
    		"comment__": "Setting for how much to preterb the agent, these are added to random links",
    	"perturb_time_min": "0.5",
		"perturb_time_max": "1",
		"min_perturb":  "100",
		"max_perturb": "150",
		"min_pertrub_duration": "0.2",
		"max_perturb_duration": "0.5",
			"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "false"
    },
    	"comment__": "Key Presses that change some of the rendered parts of the simulation",
    "rendering_key_presses": ["c", "k", "j"]
},
"PD_Biped2D_Pedistal_v2": 
{
	"config_file": "./args/genBiped2D/biped2d_full_cliff.txt",
	"time_limit": 256,
	"TerrainRL_Parameters":
    {	
    	"scenario": "sim_char",
    		"comment__": "Specific controller type to use",
    	"char_ctrl": "ct_pd",
    		"comment__": "Use simple DeepLoco HLC reward function",
    	"terrain_file": "data/terrain/precipice_humanoid.txt",
    		"comment__": "Use a different state file",
    	"state_file": "data/states/biped2D_full_stand_state.txt",
    		"comment__": "Randomly add forces to the links of the agent",
    	"enable_rand_perturbs": "true",
    		"comment__": "Setting for how much to preterb the agent, these are added to random links",
    	"perturb_time_min": "0.5",
		"perturb_time_max": "1",
		"min_perturb":  "25",
		"max_perturb": "50",
		"min_pertrub_duration": "0.2",
		"max_perturb_duration": "0.5",
			"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "false"
    },
    	"comment__": "Key Presses that change some of the rendered parts of the simulation",
    "rendering_key_presses": ["c", "k", "j"]
},
"PD_Biped2D_Pedistal_v3": 
{
	"config_file": "./args/genBiped2D/biped2d_full_cliff.txt",
	"time_limit": 256,
	"TerrainRL_Parameters":
    {	
    	"scenario": "sim_char",
    		"comment__": "Specific controller type to use",
    	"char_ctrl": "ct_pd",
    		"comment__": "Use simple DeepLoco HLC reward function",
    	"terrain_file": "data/terrain/precipice_humanoid.txt",
    		"comment__": "Use a different state file",
    	"state_file": "data/states/biped2D_full_stand_state.txt",
    		"comment__": "Randomly add forces to the links of the agent",
    	"enable_rand_perturbs": "true",
    	"enable_rand_projectiles": "true",
    		"comment__": "Setting for how much to preterb the agent, these are added to random links",
    	"perturb_time_min": "0.5",
		"perturb_time_max": "1",
		"min_perturb":  "50",
		"max_perturb": "100",
		"min_pertrub_duration": "0.2",
		"max_perturb_duration": "0.5",
		"projectile_frequency": "0.025",
			"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "false"
    },
    	"comment__": "Key Presses that change some of the rendered parts of the simulation",
    "rendering_key_presses": ["c", "k", "j"]
},
"PD_Biped2D_Treadmill_v0": 
{
	"config_file": "./args/genBiped2D/biped2d_full_treadmill.txt",
	"time_limit": 256,
	"TerrainRL_Parameters":
    {	
    		"comment__": "Specific controller type to use",
    	"char_ctrl": "ct_pd",
    		"comment__": "Use simple DeepLoco HLC reward function",
    	"terrain_file": "data/terrain/threadmill.txt"
    },
    	"comment__": "Key Presses that change some of the rendered parts of the simulation",
    "rendering_key_presses": ["c", "k", "j"]
},
"PD_Biped3D_Pedistal_v3": 
{
	"config_file": "./args/humanoid3D/LLC_waypoint_symetric_step_controller.txt",
	"time_limit": 512,
	"TerrainRL_Parameters":
    {	
    	"scenario": "sim_char",
    		"comment__": "Specific controller type to use",
    	"char_ctrl": "ct_pd",
    	"state_file": "data/states/humanoid3d_sim_walk_state_wrist_noVel.txt",
    		"comment__": "Use simple DeepLoco HLC reward function",
    	"terrain_file": "data/terrain/precipice_humanoid.txt",
    		"comment__": "Randomly add forces to the links of the agent",
    	"enable_rand_perturbs": "true",
    	"enable_rand_projectiles": "true",
    		"comment__": "Setting for how much to preterb the agent, these are added to random links",
    	"perturb_time_min": "0.5",
		"perturb_time_max": "1",
		"min_perturb":  "50",
		"max_perturb": "100",
		"min_pertrub_duration": "0.2",
		"max_perturb_duration": "0.5",
		"projectile_frequency": "0.025",
			"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "false"
    },
    	"comment__": "Key Presses that change some of the rendered parts of the simulation",
    "rendering_key_presses": ["c", "k", "j"],
    		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [365, 190, 64, 64],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [1, 1, 1]
},
"PD_Biped2D_Flat_NoPhase_v0": 
{
	"config_file": "./args/genBiped2D/biped2d_full_cliff.txt",
	"time_limit": 256,
	"TerrainRL_Parameters":
    {	
    		"comment__": "Specific controller type to use",
    	"char_ctrl": "ct_pd",
    		"comment__": "Terrain specification file",
    	"terrain_file":	"data/terrain/flat.txt"
    },
    	"comment__": "Key Presses that change some of the rendered parts of the simulation",
    "rendering_key_presses": ["c", "k", "j"]
	
},

"PD_Biped2D_Flat_NoPhase_Forward_Reward_v0": 
{
	"config_file": "./args/genBiped2D/biped2d_full_cliff.txt",
	"time_limit": 256,
	"TerrainRL_Parameters":
    {	
    		"comment__": "Specific controller type to use",
    	"char_ctrl": "ct_pd",
    		"comment__": "Terrain specification file",
    	"terrain_file":	"data/terrain/flat.txt"
    },
    	"comment__": "The reward function is the forward velocity of the agent",
    "use_forward_vel_reward": true,
    	"comment__": "Key Presses that change some of the rendered parts of the simulation",
    "rendering_key_presses": ["c", "k", "j"]
	
},
"PD_Biped2D_Walls_Terrain-v0": 
{
	"config_file": "./args/genBiped2D/biped2d_full_walls.txt",
	"time_limit": 256
},
"PD_Biped2D_Flat-v0": 
{
 	"config_file": "./args/genBiped2D/opt_args_imitate_biped_full_phase.txt",
	"time_limit": 256,
	"TerrainRL_Parameters":
    {	
    		"comment__": "Use simple DeepLoco HLC reward function",
    	"render_mode": "3d",
    		"comment__": "The type of scenario class to use.",
    	"scenario": "imitate_eval"
    }
},
"PD_Biped2D_Flat_Stand-v0": 
{
 	"config_file": "./args/genBiped2D/opt_args_imitate_biped_full_phase.txt",
	"time_limit": 256,
	"TerrainRL_Parameters":
    {	
    		"comment__": "Use simple DeepLoco HLC reward function",
    	"render_mode": "3d",
    		"comment__": "The type of scenario class to use.",
    	"scenario": "sim_char",
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "false"
    },
    	"comment__": "Use a forward velocity reward computed in the python code",
    "use_forward_vel_reward": true
},
"PD_Biped2D_Flat_Walk_MultiTask-v0": 
{
 	"config_file": "./args/genBiped2D/opt_args_imitate_biped_full_phase.txt",
	"time_limit": 256,
	"TerrainRL_Parameters":
    {	
    		"comment__": "Use simple DeepLoco HLC reward function",
    	"render_mode": "3d",
    		"comment__": "The type of scenario class to use.",
    	"scenario": "sim_char",
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "false"
    },
    	"comment__": "Use a forward velocity reward computed in the python code",
    "use_forward_vel_reward": true,
    	"comment__": "MultiTask config",
    "multitask_config":
    {
    	"type": "vel",
    		"comment__": "A mapping from task id to target velocity.",
    	"task_goal": [-2, -1.8, -1.6, -1.4, -1.2, -1.0, -0.8, -0.6, -0.4, -0.2, -0.0, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.4, 1.6, 1.8, 2.0]
    }
},
"PD_Biped2D_Flat_Walk_MultiTask-v1": 
{
 	"config_file": "./args/genBiped2D/opt_args_imitate_biped_full_phase.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": false,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": false,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": false,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": false,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
	"TerrainRL_Parameters":
    {	
    		"comment__": "Use simple DeepLoco HLC reward function",
    	"render_mode": "3d",
    		"comment__": "The type of scenario class to use.",
    	"scenario": "imitate_viz_eval",
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "false",
    	"time_warp_min": "-0.3",
    	"time_warp_max": "0.2"
    },
    	"comment__": "Use a forward velocity reward computed in the python code",
    "use_forward_vel_reward": true,
    	"comment__": "MultiTask config",
    "multitask_config":
    {
    	"type": "vel_c++",
    		"comment__": "A mapping from task id to target velocity.",
    	"task_goal": [0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2.0, 2.1, 2.2, 2.3, 2.4]
    },
    "success_distance": 2.0
},
"PD_Biped2D_MultiTask_TerrainVel-v0":
{
	"config_file": "./args/genBiped2D/biped2d_full_twotask.txt",
	"time_limit": 256,
	"TerrainRL_Parameters":
    {
    		"comment__": "Use simple DeepLoco HLC reward function",
    	"render_mode": "3d",
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "false"
    },
    	"comment__": "Key Presses that change some of the rendered parts of the simulation",
    "rendering_key_presses": ["k", "j"],
    	"comment__": "Flatten the output observation",
    "flatten_observation": true,
	"comment__": "Use a forward velocity reward computed in the python code",    
    "use_forward_vel_reward": true,
    	"comment__": "MultiTask config",
    "multitask_config":
    {
    	"type": "terrainvel",
    		"comment__": "A mapping from task id to terrain and target velocity.",
    	"task_goal": [0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2.0, 2.1, 2.2, 2.3, 2.4]
    },
    	"comment__": "Key Presses that change some of the rendered parts of the simulation",
    "rendering_key_presses": ["k", "j"],
    	"comment__": "Flatten the output observation",
    "flatten_observation": true,
    "resize_window": [128,128],
    "resize_image": [1, 48, 48],
    "camera_zoom_noise": [-0.50, -0.1],
    "add_img_noise": false,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [32, 29, 64, 64],
    "use_tiny_renderer": true,
    "success_distance": 2.0
},
"PD_Biped2D_MultiTask_Terrain-v1":
{
	"config_file": "./args/genBiped2D/biped2d_full_twotask.txt",
	"time_limit": 256,
	"TerrainRL_Parameters":
    {
    		"comment__": "Use simple DeepLoco HLC reward function",
    	"render_mode": "3d",
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    	"terrain_file": "data/terrain/twotask_humanoid.txt"
    },
    	"comment__": "Key Presses that change some of the rendered parts of the simulation",
    "rendering_key_presses": ["k", "j"],
    	"comment__": "Flatten the output observation",
    "flatten_observation": true,
		"comment__": "Use a forward velocity reward computed in the python code",    
    "use_forward_vel_reward": "distance",
		"comment__": "Use a forward velocity reward computed in the python code",
    "target_vel": 1.5,
    "multitask_config":
    {
    	"type": "terrainRand",
    		"comment__": "A mapping from task id to terrain and target velocity.",
    	"task_goal": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
    },
    "resize_window": [128,128],
    "resize_image": [1, 48, 48],
    "camera_zoom_noise": [-0.50, -0.5],
    "add_img_noise": false,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [32, 29, 64, 64],
    "use_tiny_renderer": true,
    "success_distance": 4.0,
    "add_xpos_to_state": true
},
"PD_Biped2D_Flat-v2": 
{
	"comments__": "This has a larger simulation timestep",
	"config_file": "./args/genBiped2D/biped_full_phase-v2.txt",
	"time_limit": 256
},
"PD_Biped2D_Incline-v0": 
{
	"config_file": "./args/genBiped2D/biped2d_full_inclines.txt",
	"time_limit": 256
},
"PD_Biped2D_Slopes_Mixed_Terrain-v0": 
{
	"config_file": "./args/genBiped2D/biped2d_full_slopes_mixed_with_terrain_features.txt",
	"time_limit": 256
},
"PD_Dog_2D_GRF_Imitate_30FPS_v0": 
{
	"config_file": "./args/imitation/pd/dog2d_imitate_eval_flat.txt",
	"time_limit": 256
},
"PD_Dog2D_Incline_Terrain-v0": 
{
	"config_file": "./args/genBiped2D/dog/incline_with_terrain_features.txt",
	"time_limit": 256
},
"PD_Dog2D_Steps_Terrain-v0": 
{
	"config_file": "./args/genBiped2D/dog/steps.txt",
	"time_limit": 256
},
"PD_Dog2D_Slopes_Terrain-v0": 
{
	"config_file": "./args/genBiped2D/dog/slopes_with_terrain_features.txt",
	"time_limit": 256
},
"PD_Dog2D_Gaps_Terrain-v0": 
{
	"config_file": "./args/genBiped2D/dog/gaps_with_terrain_features.txt",
	"time_limit": 256
},
"PD_Dog2D_Slopes_Mixed_Terrain-v0": 
{
	"config_file": "./args/genBiped2D/dog/slopes_mixed_with_terrain_features.txt",
	"time_limit": 256
},
"PD_Dog2D_Walls_Terrain-v0": 
{
	"config_file": "./args/genBiped2D/dog/walls.txt",
	"time_limit": 256
},
"PD_Raptor2D_Incline_Terrain-v0": 
{
	"config_file": "./args/genBiped2D/raptor/incline_with_terrain_features.txt",
	"time_limit": 256,
	"TerrainRL_Parameters":
    {	
    		"comment__": "Use simple DeepLoco HLC reward function",
    	"render_mode": "3d"
    }
},
"PD_Biped2D_MultiTask_Terrain-v0": 
{
	"config_file": "./args/genBiped2D/biped2d_full_multitask.txt",
	"time_limit": 256,
	"TerrainRL_Parameters":
    {	
    		"comment__": "Use simple DeepLoco HLC reward function",
    	"render_mode": "3d"
    },
    	"comment__": "Use a forward velocity reward computed in the python code",    
    "use_forward_vel_reward": true,
    	"comment__": "Key Presses that change some of the rendered parts of the simulation",
    "rendering_key_presses": ["k", "j"],
    	"comment__": "Flatten the output observation",
    "flatten_observation": true,
    "resize_window": [128,128],
    "resize_image": [1, 48, 48],
    "camera_zoom_noise": [-0.50, -0.1],
    "add_img_noise": false,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [32, 29, 64, 64],
    "use_tiny_renderer": true
},
"PD_Raptor2D_Steps_Terrain-v0": 
{
	"config_file": "./args/genBiped2D/raptor/steps.txt",
	"time_limit": 256
},
"PD_Raptor2D_Slopes_Terrain-v0": 
{
	"config_file": "./args/genBiped2D/raptor/slopes_with_terrain_features.txt",
	"time_limit": 256
},
"PD_Raptor2D_Gaps_Terrain-v0": 
{
	"config_file": "./args/genBiped2D/raptor/gaps_with_terrain_features.txt",
	"time_limit": 256
},
"PD_Raptor2D_Slopes_Mixed_Terrain-v0": 
{
	"config_file": "./args/genBiped2D/raptor/slopes_mixed_with_terrain_features.txt",
	"time_limit": 256
},
"PD_Raptor2D_Walls_Terrain-v0": 
{
	"config_file": "./args/genBiped2D/raptor/walls.txt",
	"time_limit": 256
},


"comment__": "These environments are new multi Character version of some of the DeepLoco environments",
"PD_Biped3D_MultiChar_LargeBlocks-v0": 
{
	"config_file": "./args/genbiped3D/multiCharacterSim.txt",
	"time_limit": 256
},    
"PD_Biped3D_MultiChar_LLC-v0": 
{
	"config_file": "./args/genbiped3D/biped3d_LLC_multi_char.txt",
	"time_limit": 256
},
"PD_Biped3D_Crowd_LargeBlocks-v0": 
{
	"config_file": "./args/genbiped3D/multiCharCrowd.txt",
	"time_limit": 256
},
"PD_Biped3D_MutliChar_LargeBlocks-v0": 
{
	"config_file": "./args/genbiped3D/multiChar.txt",
	"time_limit": 256
},
"PD_Biped3D_MutliChar_DynamicObstacles-v0": 
{
	"config_file": "./args/genbiped3D/multiCharVel.txt",
	"time_limit": 256
},
"PD_Biped3D_MutliChar_DynamicObstacles_v1": 
{
	"config_file": "./args/genbiped3D/multiCharVel.txt",
	"time_limit": 256,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Use simple DeepLoco HLC reward function",
    	"use_simple_reward": "true"
    }
},
"PD_Biped3D_MutliChar_SimpleReward_DynamicObstacles_v1": 
{
	"config_file": "./args/genbiped3D/multiCharVel.txt",
	"time_limit": 256,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Use simple DeepLoco HLC reward function",
    	"use_simple_reward": "true",
    		"comment__": "Change the location of the target position if the agent reaches the target",
    	"create_new_goals": "true"
    }
},
"PD_Biped3D_MutliChar_WithVel_LargeBlocks-v0": 
{
	"config_file": "./args/genbiped3D/multiCharWithVel.txt",
	"time_limit": 256
},        
"PD_Biped3D_MutliChar_WithVel_LargeBlocks-v1": 
{
	"config_file": "./args/genbiped3D/multiCharWithVel2.txt",
	"time_limit": 256
},
"PD_Biped3D_MutliChar_OnlyVel_v0": 
{
	"config_file": "./args/genbiped3D/multiCharHugeCrowdOnlyVel.txt",
	"time_limit": 256
},
"PD_Biped3D_MutliChar_ConcentricCircle_OnlyVel_v0": 
{
	"config_file": "./args/genbiped3D/concentricCircleCrowdOnlyVel.txt",
	"time_limit": 256
},
"PD_Biped3D_MutliChar_ConcentricCircle_OnlyVel_v1": 
{
	"config_file": "./args/genbiped3D/concentricCircleCrowdOnlyVel.txt",
	"time_limit": 256,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Use a different rotation representation for the policy learning state [quaternion|axisangle|euler]",
    	"terrain_file": "data/terrain/dynamicCharacters3D_Flat.txt"
    }
},
"PD_Biped3D_MutliChar_ConcentricCircle_OnlyVel_SimpleReward_v1": 
{
	"config_file": "./args/genbiped3D/concentricCircleCrowdOnlyVel.txt",
	"time_limit": 256,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Use a different rotation representation for the policy learning state [quaternion|axisangle|euler]",
    	"terrain_file": "data/terrain/dynamicCharacters3D_Flat.txt",
    		"comment__": "Use simple DeepLoco HLC reward function",
    	"use_simple_reward": "true",
    		"comment__": "Change the location of the target position if the agent reaches the target",
    	"create_new_goals": "true"
    }
},
"PD_Biped3D_MutliChar_ConcentricCircle_OnlyVel_SimpleReward_v2": 
{
	"config_file": "./args/genbiped3D/concentricCircleCrowdOnlyVel.txt",
	"time_limit": 256,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Use a different rotation representation for the policy learning state [quaternion|axisangle|euler]",
    	"terrain_file": "data/terrain/dynamicCharacters3D_Flat.txt",
    		"comment__": "Use simple DeepLoco HLC reward function",
    	"use_simple_reward": "true",
    		"comment__": "Change the location of the target position if the agent reaches the target",
    	"create_new_goals": "true",
    		"comment__": "Use a repulsive reward penalty when agents get close together.",
    	"use_repulsive_reward": "true",
    		"comment__": "Number of characters in the simulation in addition to the default character",
    	"num_characters": "1"
    }
},
"PD_Biped3D_MutliChar_ConcentricCircle_WithObstacles_OnlyVel_SimpleReward_v0": 
{
	"config_file": "./args/genbiped3D/concentricCircleCrowdWithObsOnlyVel.txt",
	"time_limit": 256,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Use a different rotation representation for the policy learning state [quaternion|axisangle|euler]",
    	"terrain_file": "data/terrain/dynamicCharacters3D_Obs.txt",
    		"comment__": "Use simple DeepLoco HLC reward function",
    	"use_simple_reward": "true",
    		"comment__": "Change the location of the target position if the agent reaches the target",
    	"create_new_goals": "true",
    		"comment__": "Use a repulsive reward penalty when agents get close together.",
    	"use_repulsive_reward": "true",
    		"comment__": "Number of characters in the simulation in addition to the default character",
    	"num_characters": "2"
    }
},
"PD_Biped3D_MutliChar_ScenarioSpace_WithObstacles_OnlyVel_SimpleReward_v0": 
{
	"config_file": "./args/genbiped3D/scenarioSpaceCrowdWithObsOnlyVel.txt",
	"time_limit": 256,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Use a different rotation representation for the policy learning state [quaternion|axisangle|euler]",
    	"terrain_file": "data/terrain/dynamicCharacters3D_Obs.txt",
    		"comment__": "Use simple DeepLoco HLC reward function",
    	"use_simple_reward": "true",
    		"comment__": "Change the location of the target position if the agent reaches the target",
    	"create_new_goals": "true",
    		"comment__": "Use a repulsive reward penalty when agents get close together.",
    	"use_repulsive_reward": "true"
    }
},
"PD_Biped3D_MutliChar_ScenarioSpace_WithObstacles_OnlyVel_SimpleReward_v1": 
{
	"config_file": "./args/genbiped3D/scenarioSpaceCrowdWithObsOnlyVel.txt",
	"time_limit": 256,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Use a different rotation representation for the policy learning state [quaternion|axisangle|euler]",
    	"terrain_file": "data/terrain/dynamicCharacters3D_ScenarioSpace.txt",
    		"comment__": "Use simple DeepLoco HLC reward function",
    	"use_simple_reward": "true",
    		"comment__": "Change the location of the target position if the agent reaches the target",
    	"create_new_goals": "true",
    		"comment__": "Use a repulsive reward penalty when agents get close together.",
    	"use_repulsive_reward": "true",
    		"comment__": "Number of characters in the simulation in addition to the default character",
    	"num_characters": "4"
    }
},
"PD_Biped3D_MutliChar_ScenarioSpace_WithObstacles_OnlyVel_SimpleReward_Hack_v1": 
{
	"config_file": "./args/genbiped3D/bottleneckWithObsOnlyVel.txt",
	"time_limit": 256,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Use a different terrain generation file",
    	"terrain_file": "data/terrain/dynamicCharacters3D_Obs_bottleneck.txt",
    		"comment__": "Use simple DeepLoco HLC reward function",
    	"use_simple_reward": "true",
    		"comment__": "Change the location of the target position if the agent reaches the target",
    	"create_new_goals": "true",
    		"comment__": "Use a repulsive reward penalty when agents get close together.",
    	"use_repulsive_reward": "true",
    		"comment__": "Number of characters in the simulation in addition to the default character",
    	"num_characters": "2"
    }
},
"PD_Biped3D_MutliChar_BottleNeck_WithObstacles_OnlyVel_SimpleReward_v0": 
{
	"config_file": "./args/genbiped3D/bottleneckWithObsOnlyVel.txt",
	"time_limit": 256,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Use a different terrain generation file",
    	"terrain_file": "data/terrain/dynamicCharacters3D_Obs_bottleneck.txt",
    		"comment__": "Use simple DeepLoco HLC reward function",
    	"use_simple_reward": "true",
    		"comment__": "Change the location of the target position if the agent reaches the target",
    	"create_new_goals": "true",
    		"comment__": "Use a repulsive reward penalty when agents get close together.",
    	"use_repulsive_reward": "true",
    		"comment__": "Number of characters in the simulation in addition to the default character",
    	"num_characters": "4"
    }
},
"PD_Biped3D_MutliChar_ScenarioSpace_5_WithObstacles_OnlyVel_SimpleReward_v1": 
{
	"config_file": "./args/genbiped3D/scenarioSpaceCrowdWithObsOnlyVel.txt",
	"time_limit": 256,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Use a different rotation representation for the policy learning state [quaternion|axisangle|euler]",
    	"terrain_file": "data/terrain/dynamicCharacters3D_ScenarioSpace.txt",
    		"comment__": "Use simple DeepLoco HLC reward function",
    	"use_simple_reward": "true",
    		"comment__": "Change the location of the target position if the agent reaches the target",
    	"create_new_goals": "true",
    		"comment__": "Use a repulsive reward penalty when agents get close together.",
    	"use_repulsive_reward": "true",
    		"comment__": "Number of characters in the simulation in addition to the default character",
    	"num_characters": "4"
    }
},
"PD_Biped3D_MutliChar_ScenarioSpace_Pursuite_3_WithObstacles_OnlyVel_SimpleReward_v1": 
{
	"config_file": "./args/genbiped3D/scenarioSpaceCrowdWithObsOnlyVel.txt",
	"time_limit": 256,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Use a different rotation representation for the policy learning state [quaternion|axisangle|euler]",
    	"terrain_file": "data/terrain/dynamicCharacters3D_ScenarioSpace.txt",
    		"comment__": "Use simple DeepLoco HLC reward function",
    	"use_simple_reward": "true",
    		"comment__": "Change the location of the target position if the agent reaches the target",
    	"create_new_goals": "true",
    		"comment__": "Use a repulsive reward penalty when agents get close together.",
    	"use_repulsive_reward": "true",
    		"comment__": "Number of characters in the simulation in addition to the default character",
    	"num_characters": "2",
    		"comment__": "Use a competative pursuite Reward",
    	"use_persuit_config": "true"
    }
},
"PD_Biped3D_MutliChar_Humanoid_ScenarioSpace_Pursuite_3_WithObstacles_OnlyVel_SimpleReward_v1": 
{
	"config_file": "./args/genbiped3D/scenarioSpaceCrowdWithObsOnlyVel.txt",
	"time_limit": 256,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Use a different rotation representation for the policy learning state [quaternion|axisangle|euler]",
    	"terrain_file": "data/terrain/dynamicCharacters3D_ScenarioSpace.txt",
    		"comment__": "Use simple DeepLoco HLC reward function",
    	"use_simple_reward": "true",
    		"comment__": "Change the location of the target position if the agent reaches the target",
    	"create_new_goals": "true",
    		"comment__": "Use a repulsive reward penalty when agents get close together.",
    	"use_repulsive_reward": "true",
    		"comment__": "Number of characters in the simulation in addition to the default character",
    	"num_characters": "2",
    		"comment__": "Use a competative pursuite Reward",
    	"use_persuit_config": "true",
    	"character_file": "data/characters/humanoid3d_2.txt",
		"motion_file": "data/motions/humanoid3d_walk_wrap.txt",
		"state_file": "data/states/humanoid3d_sim_walk_state_wrist.txt",
		"kin_ctrl_file": "data/controllers/humanoid3d/mocap_step_ctrl0.txt"
    }
},
"PD_Biped3D_MutliChar_ScenarioSpace_Rugby_4_WithObstacles_OnlyVel_SimpleReward_v1": 
{
	"config_file": "./args/genbiped3D/RubyCrowdWithObsOnlyVel2.txt",
	"time_limit": 256,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Use simple DeepLoco HLC reward function",
    	"use_simple_reward": "true",
    		"comment__": "Change the location of the target position if the agent reaches the target",
    	"create_new_goals": "true",
    		"comment__": "Use a repulsive reward penalty when agents get close together.",
    	"use_repulsive_reward": "true",
    		"comment__": "Number of characters in the simulation in addition to the default character",
    	"num_characters": "3"
    }
},
"PD_Biped3D_MutliChar_ScenarioSpace_Rugby_4_WithObstacles_OnlyVel_SimpleReward_v2": 
{
	"config_file": "./args/genbiped3D/RubyCrowdWithObsOnlyVel2.txt",
	"time_limit": 256,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {		"comment": "A specific version of the character controller",
    	"char_ctrl": "multi_char_crowd_vel_goal_vel",
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Use simple DeepLoco HLC reward function",
    	"use_simple_reward": "true",
    		"comment__": "Change the location of the target position if the agent reaches the target",
    	"create_new_goals": "true",
    		"comment__": "Use a repulsive reward penalty when agents get close together.",
    	"use_repulsive_reward": "true",
    		"comment__": "Number of characters in the simulation in addition to the default character",
    	"num_characters": "3"
    }
},
"PD_Biped3D_MutliChar_ScenarioSpace_Rugby_4_WithObstacles_OnlyVel_SimpleReward_v3": 
{
	"config_file": "./args/genbiped3D/RubyCrowdWithObsOnlyVel2.txt",
	"time_limit": 256,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {		"comment": "A specific version of the character controller",
    	"char_ctrl": "multi_char_crowd_vel_goal_vel",
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Use simple DeepLoco HLC reward function",
    	"use_simple_reward": "false",
    	"use_simple_distance_reward": "true",
    		"comment__": "Change the location of the target position if the agent reaches the target",
    	"create_new_goals": "true",
    		"comment__": "Use a repulsive reward penalty when agents get close together.",
    	"use_repulsive_reward": "false",
    		"comment__": "Number of characters in the simulation in addition to the default character",
    	"num_characters": "3"
    }
},
"PD_Biped3D_MutliChar_ScenarioSpace_Rugby_4_WithObstacles_OnlyVel_SimpleReward_v4": 
{
	"config_file": "./args/genbiped3D/RubyCrowdWithObsOnlyVel2.txt",
	"time_limit": 256,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {		"comment": "A specific version of the character controller",
    	"char_ctrl": "multi_char_crowd_vel_goal_vel_pos",
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Use simple DeepLoco HLC reward function",
    	"use_simple_reward": "false",
    	"use_simple_distance_reward": "true",
    		"comment__": "Change the location of the target position if the agent reaches the target",
    	"create_new_goals": "true",
    		"comment__": "Use a repulsive reward penalty when agents get close together.",
    	"use_repulsive_reward": "false",
    		"comment__": "Number of characters in the simulation in addition to the default character",
    	"num_characters": "3"
    }
},
"PD_Biped3D_MutliChar_ScenarioSpace_Rugby_2_WithObstacles_OnlyVel_SimpleReward_v5": 
{
	"config_file": "./args/genbiped3D/RubyCrowdWithObsOnlyVel2.txt",
	"time_limit": 256,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {		"comment": "A specific version of the character controller",
    	"char_ctrl": "multi_char_crowd_vel_goal_vel_pos",
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Use simple DeepLoco HLC reward function",
    	"use_simple_reward": "false",
    	"use_simple_distance_reward": "true",
    		"comment__": "Change the location of the target position if the agent reaches the target",
    	"create_new_goals": "true",
    		"comment__": "Use a repulsive reward penalty when agents get close together.",
    	"use_repulsive_reward": "false",
    		"comment__": "Number of characters in the simulation in addition to the default character",
    	"num_characters": "1"
    }
},
"PD_Biped3D_MutliChar_Humanoid_ScenarioSpace_Rugby_4_WithObstacles_OnlyVel_SimpleReward_v1": 
{
	"config_file": "./args/genbiped3D/RubyCrowdWithObsOnlyVel2.txt",
	"time_limit": 256,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Use simple DeepLoco HLC reward function",
    	"use_simple_reward": "true",
    		"comment__": "Change the location of the target position if the agent reaches the target",
    	"create_new_goals": "true",
    		"comment__": "Use a repulsive reward penalty when agents get close together.",
    	"use_repulsive_reward": "true",
    		"comment__": "Number of characters in the simulation in addition to the default character",
    	"num_characters": "3",
    	"character_file": "data/characters/humanoid3d_2.txt",
		"motion_file": "data/motions/humanoid3d_walk_wrap.txt",
		"state_file": "data/states/humanoid3d_sim_walk_state_wrist.txt",
		"kin_ctrl_file": "data/controllers/humanoid3d/mocap_step_ctrl0.txt"
    }
},
"PD_Biped3D_MutliChar_Humanoid_ScenarioSpace_Soccer_4_WithObstacles_AndOtherAgentPos_OnlyVel_SimpleReward_v1": 
{
	"config_file": "./args/genbiped3D/RubyCrowdWithObsOnlyVel2.txt",
	"time_limit": 256,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Use simple DeepLoco HLC reward function",
    	"use_simple_reward": "true",
    		"comment__": "Change the location of the target position if the agent reaches the target",
    	"create_new_goals": "true",
    		"comment__": "Use a repulsive reward penalty when agents get close together.",
    	"use_repulsive_reward": "true",
    		"comment__": "Number of characters in the simulation in addition to the default character",
    	"num_characters": "3",
    	"character_file": "data/characters/humanoid3d_colourful2.txt",
		"motion_file": "data/motions/humanoid3d_walk_wrap.txt",
		"state_file": "data/states/humanoid3d_sim_walk_state_wrist.txt",
		"kin_ctrl_file": "data/controllers/humanoid3d/mocap_step_ctrl0.txt",
    	"enable_rand_projectiles": "false",
			"comment__": "Setting for how much to preterb the agent, these are added to random links",
    	"perturb_time_min": "2.0",
		"perturb_time_max": "3.0",
		"min_perturb":  "20",
		"max_perturb": "50",
		"min_pertrub_duration": "0.1",
		"max_perturb_duration": "0.2",
		"projectile_frequency": "0.01",
		"include_arms_in_mirror": "true",
		"char_ctrl": "multi_char_crowd_vel_goal_vel_pos_otheragent_posvel"
    }
},
"PD_Humanoid3D_MutliChar_ScenarioSpace_OnlyVel_SimpleReward_v0": 
{
	"config_file": "./args/genbiped3D/scenarioSpaceCrowdWithObsOnlyVel.txt",
	"time_limit": 256,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Use a different rotation representation for the policy learning state [quaternion|axisangle|euler]",
    	"terrain_file": "data/terrain/dynamicCharacters3D_ScenarioSpace.txt",
    		"comment__": "Use simple DeepLoco HLC reward function",
    	"use_simple_reward": "true",
    		"comment__": "Number of characters in the simulation in addition to the default character",
    	"num_characters": "3",
    		"comment__": "Change the location of the target position if the agent reaches the target",
    	"create_new_goals": "true",
    		"comment__": "Use a repulsive reward penalty when agents get close together.",
    	"use_repulsive_reward": "true",
    	"character_file": "data/characters/humanoid3d_2.txt",
		"motion_file": "data/motions/humanoid3d_walk_wrap.txt",
		"state_file": "data/states/humanoid3d_sim_walk_state_wrist.txt",
		"kin_ctrl_file": "data/controllers/humanoid3d/mocap_step_ctrl0.txt"
    }
},
"PD_Humanoid3D_MutliChar_ScenarioSpace_1_OnlyVel_SimpleReward_v0": 
{
	"config_file": "./args/genbiped3D/scenarioSpaceCrowdWithObsOnlyVel.txt",
	"time_limit": 256,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Use a different rotation representation for the policy learning state [quaternion|axisangle|euler]",
    	"terrain_file": "data/terrain/dynamicCharacters3D_ScenarioSpace.txt",
    		"comment__": "Use simple DeepLoco HLC reward function",
    	"use_simple_reward": "true",
    		"comment__": "Number of characters in the simulation in addition to the default character",
    	"num_characters": "1",
    		"comment__": "Change the location of the target position if the agent reaches the target",
    	"create_new_goals": "true",
    		"comment__": "Use a repulsive reward penalty when agents get close together.",
    	"use_repulsive_reward": "true",
    	"character_file": "data/characters/humanoid3d_2.txt",
		"motion_file": "data/motions/humanoid3d_walk_wrap.txt",
		"state_file": "data/states/humanoid3d_sim_walk_state_wrist.txt",
		"kin_ctrl_file": "data/controllers/humanoid3d/mocap_step_ctrl0.txt"
    }
},
"PD_Humanoid3D_MutliChar_ScenarioSpace_5_OnlyVel_SimpleReward_v1": 
{
	"config_file": "./args/genbiped3D/scenarioSpaceCrowdWithObsOnlyVel.txt",
	"time_limit": 256,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Use a different rotation representation for the policy learning state [quaternion|axisangle|euler]",
    	"terrain_file": "data/terrain/dynamicCharacters3D_ScenarioSpace.txt",
    		"comment__": "Use simple DeepLoco HLC reward function",
    	"use_simple_reward": "true",
    	"use_simple_distance_reward": "true",
    		"comment__": "Number of characters in the simulation in addition to the default character",
    	"num_characters": "4",
    		"comment__": "Change the location of the target position if the agent reaches the target",
    	"create_new_goals": "true",
    		"comment__": "Use a repulsive reward penalty when agents get close together.",
    	"use_repulsive_reward": "true",
    		"comment__": "Randomly add forces to the links of the agent",
    	"enable_rand_perturbs": "false",
    	"character_file": "data/characters/humanoid3d_colourful2.txt",
		"motion_file": "data/motions/humanoid3d_walk_wrap.txt",
		"state_file": "data/states/humanoid3d_sim_walk_state_wrist.txt",
		"kin_ctrl_file": "data/controllers/humanoid3d/mocap_step_ctrl0.txt",
    	"enable_rand_projectiles": "false",
			"comment__": "Setting for how much to preterb the agent, these are added to random links",
    	"perturb_time_min": "2.0",
		"perturb_time_max": "3.0",
		"min_perturb":  "20",
		"max_perturb": "50",
		"min_pertrub_duration": "0.1",
		"max_perturb_duration": "0.2",
		"projectile_frequency": "0.01",
		"include_arms_in_mirror": "true"
    }
},
"PD_Humanoid3D_MutliChar_ScenarioSpace_10_OnlyVel_SimpleReward_v1": 
{
	"config_file": "./args/genbiped3D/scenarioSpaceCrowdWithObsOnlyVel.txt",
	"time_limit": 256,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Use a different rotation representation for the policy learning state [quaternion|axisangle|euler]",
    	"terrain_file": "data/terrain/dynamicCharacters3D_ScenarioSpace.txt",
    		"comment__": "Use simple DeepLoco HLC reward function",
    	"use_simple_reward": "true",
    	"use_simple_distance_reward": "true",
    		"comment__": "Number of characters in the simulation in addition to the default character",
    	"num_characters": "9",
    		"comment__": "Change the location of the target position if the agent reaches the target",
    	"create_new_goals": "true",
    		"comment__": "Use a repulsive reward penalty when agents get close together.",
    	"use_repulsive_reward": "true",
    		"comment__": "Randomly add forces to the links of the agent",
    	"enable_rand_perturbs": "false",
    	"character_file": "data/characters/humanoid3d_colourful2.txt",
		"motion_file": "data/motions/humanoid3d_walk_wrap.txt",
		"state_file": "data/states/humanoid3d_sim_walk_state_wrist.txt",
		"kin_ctrl_file": "data/controllers/humanoid3d/mocap_step_ctrl0.txt",
    	"enable_rand_projectiles": "false",
			"comment__": "Setting for how much to preterb the agent, these are added to random links",
    	"perturb_time_min": "2.0",
		"perturb_time_max": "3.0",
		"min_perturb":  "20",
		"max_perturb": "50",
		"min_pertrub_duration": "0.1",
		"max_perturb_duration": "0.2",
		"projectile_frequency": "0.01",
		"include_arms_in_mirror": "true"
    }
},
"PD_Humanoid3D_MutliChar_ConcentricCircle_5_OnlyVel_SimpleReward_v3": 
{
	"config_file": "./args/genbiped3D/concentricCircleCrowdOnlyVel.txt",
	"time_limit": 256,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Use a different rotation representation for the policy learning state [quaternion|axisangle|euler]",
    	"terrain_file": "data/terrain/dynamicCharacters3D_Obs_0.txt",
    		"comment__": "Use simple DeepLoco HLC reward function",
    	"use_simple_reward": "true",
    		"comment__": "Number of characters in the simulation in addition to the default character",
    	"num_characters": "4",
    		"comment__": "Change the location of the target position if the agent reaches the target",
    	"create_new_goals": "true",
    		"comment__": "Use a repulsive reward penalty when agents get close together.",
    	"use_repulsive_reward": "true",
    		"comment__": "Randomly add forces to the links of the agent",
    	"enable_rand_perturbs": "false",
    	"character_file": "data/characters/humanoid3d_colourful2.txt",
		"motion_file": "data/motions/humanoid3d_walk_wrap.txt",
		"state_file": "data/states/humanoid3d_sim_walk_state_wrist.txt",
		"kin_ctrl_file": "data/controllers/humanoid3d/mocap_step_ctrl0.txt",
    	"enable_rand_projectiles": "false",
			"comment__": "Setting for how much to preterb the agent, these are added to random links",
    	"perturb_time_min": "2.0",
		"perturb_time_max": "3.0",
		"min_perturb":  "20",
		"max_perturb": "50",
		"min_pertrub_duration": "0.1",
		"max_perturb_duration": "0.2",
		"projectile_frequency": "0.01",
		"include_arms_in_mirror": "true"
    		
    }
},
"PD_Humanoid3D_MutliChar_ConcentricCircle_10_OnlyVel_SimpleReward_v3": 
{
	"config_file": "./args/genbiped3D/concentricCircleCrowdOnlyVel.txt",
	"time_limit": 256,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Use a different rotation representation for the policy learning state [quaternion|axisangle|euler]",
    	"terrain_file": "data/terrain/dynamicCharacters3D_Obs_0.txt",
    		"comment__": "Use simple DeepLoco HLC reward function",
    	"use_simple_reward": "true",
    		"comment__": "Number of characters in the simulation in addition to the default character",
    	"num_characters": "9",
    		"comment__": "Change the location of the target position if the agent reaches the target",
    	"create_new_goals": "true",
    		"comment__": "Use a repulsive reward penalty when agents get close together.",
    	"use_repulsive_reward": "true",
    		"comment__": "Randomly add forces to the links of the agent",
    	"enable_rand_perturbs": "false",
    	"character_file": "data/characters/humanoid3d_colourful2.txt",
		"motion_file": "data/motions/humanoid3d_walk_wrap.txt",
		"state_file": "data/states/humanoid3d_sim_walk_state_wrist.txt",
		"kin_ctrl_file": "data/controllers/humanoid3d/mocap_step_ctrl0.txt",
    	"enable_rand_projectiles": "false",
			"comment__": "Setting for how much to preterb the agent, these are added to random links",
    	"perturb_time_min": "2.0",
		"perturb_time_max": "3.0",
		"min_perturb":  "20",
		"max_perturb": "50",
		"min_pertrub_duration": "0.1",
		"max_perturb_duration": "0.2",
		"projectile_frequency": "0.01",
		"include_arms_in_mirror": "true"
    		
    }
},
"PD_Humanoid3D_MutliChar_ConcentricCircle_WithObs_OnlyVel_SimpleReward_v1": 
{
	"config_file": "./args/genbiped3D/concentricCircleCrowdWithObsOnlyVel.txt",
	"time_limit": 256,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Use a different rotation representation for the policy learning state [quaternion|axisangle|euler]",
    	"terrain_file": "data/terrain/dynamicCharacters3D_Obs.txt",
    		"comment__": "Use simple DeepLoco HLC reward function",
    	"use_simple_reward": "true",
    		"comment__": "Number of characters in the simulation in addition to the default character",
    	"num_characters": "4",
    		"comment__": "Change the location of the target position if the agent reaches the target",
    	"create_new_goals": "true",
    		"comment__": "Use a repulsive reward penalty when agents get close together.",
    	"use_repulsive_reward": "true",
    	"character_file": "data/characters/humanoid3d_colourful2.txt",
		"motion_file": "data/motions/humanoid3d_walk_wrap.txt",
		"state_file": "data/states/humanoid3d_sim_walk_state_wrist.txt",
		"kin_ctrl_file": "data/controllers/humanoid3d/mocap_step_ctrl0.txt",
		"enable_rand_projectiles": "false",
			"comment__": "Setting for how much to preterb the agent, these are added to random links",
    	"perturb_time_min": "2.0",
		"perturb_time_max": "3.0",
		"min_perturb":  "20",
		"max_perturb": "50",
		"min_pertrub_duration": "0.1",
		"max_perturb_duration": "0.2",
		"projectile_frequency": "0.01",
		"include_arms_in_mirror": "true"
    }
},
"PD_Humanoid3D_MutliChar_BottleNeck_WithObstacles_OnlyVel_SimpleReward_v0": 
{
	"config_file": "./args/genbiped3D/bottleneckWithObsOnlyVel.txt",
	"time_limit": 256,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Use a different terrain generation file",
    	"terrain_file": "data/terrain/dynamicCharacters3D_Obs_bottleneck.txt",
    		"comment__": "Use simple DeepLoco HLC reward function",
    	"use_simple_reward": "true",
    		"comment__": "Change the location of the target position if the agent reaches the target",
    	"create_new_goals": "true",
    		"comment__": "Use a repulsive reward penalty when agents get close together.",
    	"use_repulsive_reward": "true",
    		"comment__": "Number of characters in the simulation in addition to the default character",
    	"num_characters": "4",
    		"comment__": "Change the location of the target position if the agent reaches the target",
    	"create_new_goals": "true",
    		"comment__": "Use a repulsive reward penalty when agents get close together.",
    	"use_repulsive_reward": "true",
    	"character_file": "data/characters/humanoid3d_colourful2.txt",
		"motion_file": "data/motions/humanoid3d_walk_wrap.txt",
		"state_file": "data/states/humanoid3d_sim_walk_state_wrist.txt",
		"kin_ctrl_file": "data/controllers/humanoid3d/mocap_step_ctrl0.txt",
		"enable_rand_projectiles": "false",
			"comment__": "Setting for how much to preterb the agent, these are added to random links",
    	"perturb_time_min": "2.0",
		"perturb_time_max": "3.0",
		"min_perturb":  "20",
		"max_perturb": "50",
		"min_pertrub_duration": "0.1",
		"max_perturb_duration": "0.2",
		"projectile_frequency": "0.01",
		"include_arms_in_mirror": "true"
    }
},
"PD_Humanoid3D_MutliChar_BottleNeck_WithObstacles_10_OnlyVel_SimpleReward_v0": 
{
	"config_file": "./args/genbiped3D/bottleneckWithObsOnlyVel.txt",
	"time_limit": 256,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Use a different terrain generation file",
    	"terrain_file": "data/terrain/dynamicCharacters3D_Obs_bottleneck.txt",
    		"comment__": "Use simple DeepLoco HLC reward function",
    	"use_simple_reward": "true",
    		"comment__": "Change the location of the target position if the agent reaches the target",
    	"create_new_goals": "true",
    		"comment__": "Use a repulsive reward penalty when agents get close together.",
    	"use_repulsive_reward": "true",
    		"comment__": "Number of characters in the simulation in addition to the default character",
    	"num_characters": "9",
    		"comment__": "Change the location of the target position if the agent reaches the target",
    	"create_new_goals": "true",
    		"comment__": "Use a repulsive reward penalty when agents get close together.",
    	"use_repulsive_reward": "true",
    	"character_file": "data/characters/humanoid3d_colourful2.txt",
		"motion_file": "data/motions/humanoid3d_walk_wrap.txt",
		"state_file": "data/states/humanoid3d_sim_walk_state_wrist.txt",
		"kin_ctrl_file": "data/controllers/humanoid3d/mocap_step_ctrl0.txt",
		"enable_rand_projectiles": "false",
			"comment__": "Setting for how much to preterb the agent, these are added to random links",
    	"perturb_time_min": "2.0",
		"perturb_time_max": "3.0",
		"min_perturb":  "20",
		"max_perturb": "50",
		"min_pertrub_duration": "0.1",
		"max_perturb_duration": "0.2",
		"projectile_frequency": "0.01",
		"include_arms_in_mirror": "true"
    }
},
"PD_Biped3D_MutliChar_ConcentricCircle_5_OnlyVel_v0": 
{
	"config_file": "./args/genbiped3D/concentricCircleCrowdOnlyVel.txt",
	"time_limit": 256,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Use a different rotation representation for the policy learning state [quaternion|axisangle|euler]",
    	"terrain_file": "data/terrain/dynamicCharacters3D_Flat.txt",
    		"comment__": "Number of characters in the simulation in addition to the default character",
    	"num_characters": "4"
    }
},
"PD_Biped3D_MutliChar_ConcentricCircle_5_OnlyVel_v1": 
{
	"config_file": "./args/genbiped3D/concentricCircleCrowdOnlyVel.txt",
	"time_limit": 256,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Use a different rotation representation for the policy learning state [quaternion|axisangle|euler]",
    	"terrain_file": "data/terrain/dynamicCharacters3D_Flat.txt",
    		"comment__": "Number of characters in the simulation in addition to the default character",
    	"num_characters": "4"
    }
},
"PD_Biped3D_MutliChar_ConcentricCircle_5_OnlyVel_SimpleReward_v1": 
{
	"config_file": "./args/genbiped3D/concentricCircleCrowdOnlyVel.txt",
	"time_limit": 256,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Use a different rotation representation for the policy learning state [quaternion|axisangle|euler]",
    	"terrain_file": "data/terrain/dynamicCharacters3D_Flat.txt",
    		"comment__": "Use simple DeepLoco HLC reward function",
    	"use_simple_reward": "true",
    		"comment__": "Number of characters in the simulation in addition to the default character",
    	"num_characters": "4",
    		"comment__": "Change the location of the target position if the agent reaches the target",
    	"create_new_goals": "true"
    }
},
"PD_Biped3D_MutliChar_ConcentricCircle_5_OnlyVel_SimpleReward_v2": 
{
	"config_file": "./args/genbiped3D/concentricCircleCrowdOnlyVel.txt",
	"time_limit": 256,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Use a different rotation representation for the policy learning state [quaternion|axisangle|euler]",
    	"terrain_file": "data/terrain/dynamicCharacters3D_Flat.txt",
    		"comment__": "Use simple DeepLoco HLC reward function",
    	"use_simple_reward": "true",
    		"comment__": "Number of characters in the simulation in addition to the default character",
    	"num_characters": "4",
    		"comment__": "Change the location of the target position if the agent reaches the target",
    	"create_new_goals": "true",
    		"comment__": "Use a repulsive reward penalty when agents get close together.",
    	"use_repulsive_reward": "true"
    		
    }
},
"PD_Biped3D_MutliChar_ConcentricCircle_5_OnlyVel_SimpleReward_v3": 
{
	"config_file": "./args/genbiped3D/concentricCircleCrowdOnlyVel.txt",
	"time_limit": 256,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Use a different rotation representation for the policy learning state [quaternion|axisangle|euler]",
    	"terrain_file": "data/terrain/dynamicCharacters3D_Obs_0.txt",
    		"comment__": "Use simple DeepLoco HLC reward function",
    	"use_simple_reward": "true",
    		"comment__": "Number of characters in the simulation in addition to the default character",
    	"num_characters": "4",
    		"comment__": "Change the location of the target position if the agent reaches the target",
    	"create_new_goals": "true",
    		"comment__": "Use a repulsive reward penalty when agents get close together.",
    	"use_repulsive_reward": "true"
    		
    }
},
"PD_Biped3D_MutliChar_ConcentricCircle_3_OnlyVel_SimpleReward_v3": 
{
	"config_file": "./args/genbiped3D/concentricCircleCrowdOnlyVel.txt",
	"time_limit": 256,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Use a different rotation representation for the policy learning state [quaternion|axisangle|euler]",
    	"terrain_file": "data/terrain/dynamicCharacters3D_Obs_0.txt",
    		"comment__": "Use simple DeepLoco HLC reward function",
    	"use_simple_reward": "true",
    		"comment__": "Number of characters in the simulation in addition to the default character",
    	"num_characters": "2",
    		"comment__": "Change the location of the target position if the agent reaches the target",
    	"create_new_goals": "true",
    		"comment__": "Use a repulsive reward penalty when agents get close together.",
    	"use_repulsive_reward": "true"
    		
    }
},
"PD_Biped3D_MutliChar_ConcentricCircle_5_WithObstacles_OnlyVel_SimpleReward_v0": 
{
	"config_file": "./args/genbiped3D/concentricCircleCrowdWithObsOnlyVel.txt",
	"time_limit": 256,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Use a different rotation representation for the policy learning state [quaternion|axisangle|euler]",
    	"terrain_file": "data/terrain/dynamicCharacters3D_Obs.txt",
    		"comment__": "Use simple DeepLoco HLC reward function",
    	"use_simple_reward": "true",
    		"comment__": "Number of characters in the simulation in addition to the default character",
    	"num_characters": "4",
    		"comment__": "Change the location of the target position if the agent reaches the target",
    	"create_new_goals": "true",
    		"comment__": "Use a repulsive reward penalty when agents get close together.",
    	"use_repulsive_reward": "true"
    		
    }
},
"PD_Humanoid3D_MutliChar_ConcentricCircle_5_OnlyVel_SimpleReward_v0": 
{
	"config_file": "./args/genbiped3D/concentricCircleHumanoidCrowdOnlyVel.txt",
	"time_limit": 256,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Use a different rotation representation for the policy learning state [quaternion|axisangle|euler]",
    	"terrain_file": "data/terrain/dynamicCharacters3D_Flat.txt",
    		"comment__": "Use simple DeepLoco HLC reward function",
    	"use_simple_reward": "true",
    		"comment__": "Number of characters in the simulation in addition to the default character",
    	"num_characters": "4",
    		"comment__": "Change the location of the target position if the agent reaches the target",
    	"create_new_goals": "true",
    		"comment__": "Use a repulsive reward penalty when agents get close together.",
    	"use_repulsive_reward": "true"
    }
},
"PD_Humanoid3D_MutliChar_ConcentricCircle_OnlyVel_SimpleReward_v0": 
{
	"config_file": "./args/genbiped3D/concentricCircleHumanoidCrowdOnlyVel.txt",
	"time_limit": 256,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Use a different rotation representation for the policy learning state [quaternion|axisangle|euler]",
    	"terrain_file": "data/terrain/dynamicCharacters3D_Flat.txt",
    		"comment__": "Use simple DeepLoco HLC reward function",
    	"use_simple_reward": "true",
    		"comment__": "Number of characters in the simulation in addition to the default character",
    	"num_characters": "3",
    		"comment__": "Change the location of the target position if the agent reaches the target",
    	"create_new_goals": "true",
    		"comment__": "Use a repulsive reward penalty when agents get close together.",
    	"use_repulsive_reward": "true"
    }
},
"PD_Biped3D_MutliChar_DensityMod_OnlyVel_v1": 
{
	"config_file": "./args/genbiped3D/multiCharDensityModulation.txt",
	"time_limit": 256,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Use a different rotation representation for the policy learning state [quaternion|axisangle|euler]",
    	"terrain_file": "data/terrain/dynamicCharacters3D_Flat.txt"
	}
},
"PD_Biped3D_MutliChar_Crowd_WithVel_LargeBlocks-v0": 
{
	"config_file": "./args/genbiped3D/multiCharCrowdWithVel2.txt",
	"time_limit": 256
},    
"comment__": "These environments are from the DeepLoco work",
"PD_Biped3D_HLC_PathFollowing_v0": 
{
	"config_file": "./args/genbiped3D/biped3d_HLC_waypoint_step_controller.txt",
	"time_limit": 256
},
"PD_Biped3D_HLC_LargeBlocks-v0": 
{
	"config_file": "./args/genbiped3D/biped3d_HLC_LargeBlocks.json",
	"time_limit": 256
},        
"PD_Biped3D_LLC_General_Step-v0": 
{
	"config_file": "./args/genbiped3D/biped3d_LLC_waypoint_general_step_controller.txt",
	"time_limit": 512
},        
"PD_Biped3D_LLC_Symetric_Step-v0": 
{
	"config_file": "./args/genbiped3D/biped3d_LLC_waypoint_sysemtric_step_controller.txt",
	"time_limit": 512
},        
"PD_Biped3D_LLC_Symetric_Step_v1": 
{
	"config_file": "./args/genbiped3D/biped3d_LLC_waypoint_sysemtric_step_controller.txt",
	"time_limit": 512,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "If true the initial faceing direction of the agent will be random",
    	"randomize_initial_rotation": "true"
    }
},        
"PD_Biped3D_LLC_Symetric_Step_v0_MultiAgent_Terrain": 
{
	"config_file": "./args/genbiped3D/biped3d_LLC_waypoint_sysemtric_step_controller.txt",
	"time_limit": 512,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Use a different rotation representation for the policy learning state [quaternion|axisangle|euler]",
    	"terrain_file": "data/terrain/dynamicCharacters3D_Flat.txt"
    }
},        
"PD_Biped3D_LLC_Symetric_Step_MultiAgent_Terrain_v1": 
{
	"config_file": "./args/genbiped3D/biped3d_LLC_waypoint_sysemtric_step_controller.txt",
	"time_limit": 512,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Use a different rotation representation for the policy learning state [quaternion|axisangle|euler]",
    	"terrain_file": "data/terrain/dynamicCharacters3D_Flat.txt",
    		"comment__": "If true the initial faceing direction of the agent will be random",
    	"randomize_initial_rotation": "true"
    }
},        
"PD_Biped3D_LLC_Symetric_Step_MultiAgent_Terrain_v2": 
{
	"config_file": "./args/genbiped3D/biped3d_LLC_waypoint_sysemtric_step_controller.txt",
	"time_limit": 512,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Use a different rotation representation for the policy learning state [quaternion|axisangle|euler]",
    	"terrain_file": "data/terrain/dynamicCharacters3D_Flat.txt",
    		"comment__": "If true the initial faceing direction of the agent will be random",
    	"randomize_initial_rotation": "true",
    		"comment__": "Add a joint torque penalty to the reward",
    	"add_torque_penalty": "true",
    		"comment__": "Randomly add forces to the links of the agent",
    	"enable_rand_perturbs": "true"
    }
},        
"PD_Biped3D_LLC_Symetric_Step_MultiAgent_Terrain_WithObs_v0": 
{
	"config_file": "./args/genbiped3D/biped3d_LLC_waypoint_sysemtric_step_controller.txt",
	"time_limit": 512,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Use a different rotation representation for the policy learning state [quaternion|axisangle|euler]",
    	"terrain_file": "data/terrain/dynamicCharacters3D_Obs_0.txt",
    		"comment__": "If true the initial faceing direction of the agent will be random",
    	"randomize_initial_rotation": "true",
    		"comment__": "Add a joint torque penalty to the reward",
    	"add_torque_penalty": "true",
    		"comment__": "Randomly add forces to the links of the agent",
    	"enable_rand_perturbs": "true"
    }
},        
"PD_Biped3D_LLC_Symetric_Step_MultiAgent_Terrain_WithObs_v1": 
{
	"config_file": "./args/genbiped3D/biped3d_LLC_waypoint_sysemtric_step_controller.txt",
	"time_limit": 512,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Use a different rotation representation for the policy learning state [quaternion|axisangle|euler]",
    	"terrain_file": "data/terrain/dynamicCharacters3D_Obs_0.txt",
    		"comment__": "If true the initial faceing direction of the agent will be random",
    	"randomize_initial_rotation": "true",
    		"comment__": "Add a joint torque penalty to the reward",
    	"add_torque_penalty": "true",
    		"comment__": "Randomly add forces to the links of the agent",
    	"enable_rand_perturbs": "true",
    	"enable_rand_projectiles": "true",
    		"comment__": "Setting for how much to preterb the agent, these are added to random links",
    	"perturb_time_min": "0.5",
		"perturb_time_max": "1",
		"min_perturb":  "50",
		"max_perturb": "100",
		"min_pertrub_duration": "0.2",
		"max_perturb_duration": "0.5",
		"step_sharp_turn_prob": "0.25",
		"projectile_frequency": "0.025"
    }
},        
"PD_Humanoid3D_LLC_Symetric_Step_MultiAgent_Terrain_WithObs_v0": 
{
	"config_file": "./args/genbiped3D/biped3d_LLC_waypoint_sysemtric_step_controller.txt",
	"time_limit": 512,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Use a different rotation representation for the policy learning state [quaternion|axisangle|euler]",
     	"terrain_file": "data/terrain/dynamicCharacters3D_Obs_0.txt",
    		"comment__": "If true the initial faceing direction of the agent will be random",
    	"randomize_initial_rotation": "true",
    		"comment__": "Add a joint torque penalty to the reward",
    	"add_torque_penalty": "true",
    		"comment__": "Randomly add forces to the links of the agent",
    	"enable_rand_perturbs": "true",
    	"character_file": "data/characters/humanoid3d_colourful2.txt",
		"motion_file": "data/motions/humanoid3d_walk_wrap.txt",
		"state_file": "data/states/humanoid3d_sim_walk_state_wrist.txt",
		"kin_ctrl_file": "data/controllers/humanoid3d/mocap_step_ctrl0.txt"
    }
},        
"PD_Humanoid3D_LLC_Symetric_Step_MultiAgent_Terrain_WithObs_Pushes_v1": 
{
	"config_file": "./args/genbiped3D/biped3d_LLC_waypoint_sysemtric_step_controller.txt",
	"time_limit": 512,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Use a different rotation representation for the policy learning state [quaternion|axisangle|euler]",
     	"terrain_file": "data/terrain/dynamicCharacters3D_Obs_0.txt",
    		"comment__": "If true the initial faceing direction of the agent will be random",
    	"randomize_initial_rotation": "true",
    		"comment__": "Add a joint torque penalty to the reward",
    	"add_torque_penalty": "true",
    		"comment__": "Randomly add forces to the links of the agent",
    	"enable_rand_perturbs": "true",
    	"character_file": "data/characters/humanoid3d_colourful2.txt",
		"motion_file": "data/motions/humanoid3d_walk_wrap.txt",
		"state_file": "data/states/humanoid3d_sim_walk_state_wrist.txt",
		"kin_ctrl_file": "data/controllers/humanoid3d/mocap_step_ctrl0.txt",
    	"enable_rand_projectiles": "true",
			"comment__": "Setting for how much to preterb the agent, these are added to random links",
    	"perturb_time_min": "2.0",
		"perturb_time_max": "3.0",
		"min_perturb":  "20",
		"max_perturb": "50",
		"min_pertrub_duration": "0.1",
		"max_perturb_duration": "0.2",
		"projectile_frequency": "0.01",
		"include_arms_in_mirror": "true"
    }
},        
"PD_Humanoid3D_LLC_Symetric_Step_MultiAgent_Terrain_WithObs_v1": 
{
	"config_file": "./args/genbiped3D/biped3d_LLC_waypoint_sysemtric_step_controller.txt",
	"time_limit": 512,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Use a different rotation representation for the policy learning state [quaternion|axisangle|euler]",
     	"terrain_file": "data/terrain/dynamicCharacters3D_Obs_0.txt",
    		"comment__": "If true the initial faceing direction of the agent will be random",
    	"randomize_initial_rotation": "false",
    		"comment__": "Add a joint torque penalty to the reward",
    	"add_torque_penalty": "true",
    		"comment__": "Randomly add forces to the links of the agent",
    	"enable_rand_perturbs": "true",
    	"character_file": "data/characters/humanoid3d_colourful2.txt",
		"motion_file": "data/motions/humanoid3d_walk_wrap.txt",
		"state_file": "data/states/humanoid3d_sim_walk_state_wrist.txt",
		"kin_ctrl_file": "data/controllers/humanoid3d/mocap_step_ctrl0.txt",
    	"enable_rand_projectiles": "true",
			"comment__": "Setting for how much to preterb the agent, these are added to random links",
    	"perturb_time_min": "2.0",
		"perturb_time_max": "3.0",
		"min_perturb":  "20",
		"max_perturb": "50",
		"min_pertrub_duration": "0.1",
		"max_perturb_duration": "0.2",
		"projectile_frequency": "0.01",
		"include_arms_in_mirror": "true",
		"target_reset_dist": "2.5",
		"enable_rand_target_pos": "true"
    }
},        
"PD_Humanoid3D_LLC_Symetric_Step_MultiAgent_Terrain_WithObs_NewContacts_v0": 
{
	"config_file": "./args/genbiped3D/biped3d_LLC_waypoint_sysemtric_step_controller.txt",
	"time_limit": 512,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Use a different rotation representation for the policy learning state [quaternion|axisangle|euler]",
     	"terrain_file": "data/terrain/dynamicCharacters3D_Obs_0.txt",
    		"comment__": "If true the initial faceing direction of the agent will be random",
    	"randomize_initial_rotation": "true",
    		"comment__": "Add a joint torque penalty to the reward",
    	"add_torque_penalty": "true",
    		"comment__": "Randomly add forces to the links of the agent",
    	"enable_rand_perturbs": "false",
    	"character_file": "data/characters/humanoid3d_colourful_contacts2.txt",
		"motion_file": "data/motions/humanoid3d_walk_wrap.txt",
		"state_file": "data/states/humanoid3d_sim_walk_state_wrist.txt",
		"kin_ctrl_file": "data/controllers/humanoid3d/mocap_step_ctrl0.txt",
    	"enable_rand_projectiles": "false",
			"comment__": "Setting for how much to preterb the agent, these are added to random links",
    	"perturb_time_min": "2.0",
		"perturb_time_max": "3.0",
		"min_perturb":  "20",
		"max_perturb": "50",
		"min_pertrub_duration": "0.1",
		"max_perturb_duration": "0.2",
		"projectile_frequency": "0.01"
    }
},
"PD_humanoid3D_LLC_Symetric_Step": 
{
	"config_file": "./args/humanoid3D/LLC_waypoint_symetric_step_controller.txt",
	"time_limit": 512,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "false"
    }
},        
"PD_humanoid3D_LLC_Symetric_Step_MultiAgent_Terrain": 
{
	"config_file": "./args/humanoid3D/LLC_waypoint_symetric_step_controller.txt",
	"time_limit": 512,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "false",
    		"comment__": "Use a different rotation representation for the policy learning state [quaternion|axisangle|euler]",
    	"terrain_file": "data/terrain/dynamicCharacters3D_Flat.txt",
    		"comment__": "If true the initial faceing direction of the agent will be random",
    	"randomize_initial_rotation": "true"
    }
},        
"PD_humanoid3D_LLC_Symetric_Step_MultiAgent_Terrain_v1": 
{
	"config_file": "./args/humanoid3D/LLC_waypoint_symetric_step_controller.txt",
	"time_limit": 512,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "false",
    		"comment__": "Use a different rotation representation for the policy learning state [quaternion|axisangle|euler]",
    	"terrain_file": "data/terrain/dynamicCharacters3D_Flat.txt",
    		"comment__": "If true the initial faceing direction of the agent will be random",
    	"randomize_initial_rotation": "true",
    		"comment__": "Add a joint torque penalty to the reward",
    	"add_torque_penalty": "true"
    }
},        
"PD_humanoid3D_LLC_Symetric_Step_MultiAgent_Terrain_v2": 
{
	"config_file": "./args/humanoid3D/LLC_waypoint_symetric_step_controller.txt",
	"time_limit": 512,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "false",
    		"comment__": "Use a different rotation representation for the policy learning state [quaternion|axisangle|euler]",
    	"terrain_file": "data/terrain/dynamicCharacters3D_Flat.txt",
    		"comment__": "If true the initial faceing direction of the agent will be random",
    	"randomize_initial_rotation": "true",
    		"comment__": "Add a joint torque penalty to the reward",
    	"add_torque_penalty": "true",
    		"comment__": "Randomly add forces to the links of the agent",
    	"enable_rand_perturbs": "true"
    }
},        
"PD_humanoid3D_LLC_GetUp_MultiAgent_Terrain_v2": 
{
	"config_file": "./args/genbiped3D/imitation/imitate_biped3d_phase.txt",
	"time_limit": 512,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Use a different rotation representation for the policy learning state [quaternion|axisangle|euler]",
     	"terrain_file": "data/terrain/dynamicCharacters3D_Obs_0.txt",
    		"comment__": "If true the initial faceing direction of the agent will be random",
    	"randomize_initial_rotation": "true",
    		"comment__": "Add a joint torque penalty to the reward",
    	"add_torque_penalty": "true",
    		"comment__": "Randomly add forces to the links of the agent",
    	"enable_rand_perturbs": "false",
    	"character_file": "data/characters/humanoid3d_colourful_contacts2.txt",
		"motion_file": "data/motions/humanoid3d_getup_facedown.txt",
		"state_file": "data/states/humanoid3d_sim_walk_state_wrist.txt"
    }
},
"PD_Biped3D_LLC_Symetric_Step-v1": 
{
	"config_file": "./args/genbiped3D/biped3d_LLC_waypoint_symetric_step_controller-v2.txt",
	"time_limit": 256
},        
"PD_Biped3D_HLC_DynamicsObstacles-v0": 
{
	"config_file": "./args/genbiped3D/biped3d_HLC_DynamicObstacles.json",
	"time_limit": 256
},        
"PD_Biped3D_HLC_DynamicsObstacles-v1": 
{
	"comment__": "This version uses the symetric LLC",
	"config_file": "./args/genbiped3D/biped3d_HLC_DynamicObstacles-v2.json",
	"time_limit": 256
},        
"PD_Biped3D_HLC_Soccer-v0": 
{
	"config_file": "./args/genbiped3D/biped3d_HLC_Soccer.json",
	"time_limit": 256
},        
"PD-Biped3D-HLC-Soccer-v1": 
{
	"config_file": "./args/genbiped3D/imitate_target_terr_biped3d_soccer.txt",
	"time_limit": 256,
    	"comment__": "Key Presses that change some of the rendered parts of the simulation",
    "rendering_key_presses": ["k", "j"]
},        
"PD-Biped3D-HLC-Obstacles-v2": 
{
	"config_file": "./args/genbiped3D/biped_step_largeBlocks_biped3d2.txt",
	"time_limit": 4098,
    	"comment__": "Key Presses that change some of the rendered parts of the simulation",
    "rendering_key_presses": ["k", "j"],
    "TerrainRL_Parameters":
    {	
    		"comment__": "Amount to change the caracter zoom focus.",
    	"camera_zoom": "-30.25",
    		"comment__": "Amount to change the caracter zoom focus.",
    	"camera_height": "10.25"
    }
},        
"PD_Biped3D_HLC_Forest-v0": 
{
	"config_file": "./args/genbiped3D/biped3d_HLC_Forest.json",
	"time_limit": 256
},        
"PD_Biped3D_HLC_Conveyors-v0": 
{
	"config_file": "./args/genbiped3D/biped3d_HLC_Conveyors.json",
	"time_limit": 256
},        
"PD_Biped3D_HLC_Conveyors_Wide-v0": 
{
	"config_file": "./args/genbiped3D/biped3d_HLC_Conveyors_Wide.json",
	"time_limit": 256
},        
"PD_Biped3D_LLC_Run_FootStep-v0": 
{
	"config_file": "./args/genbiped3D/biped3d_LLC_Run_FootStep_controller.txt",
	"time_limit": 256
},
"PD_Biped3D_Terrain_Trail_Hard-v0": 
{
	"config_file": "./args/genbiped3D/imitate_target_terr_biped3d_trail.txt",
	"time_limit": 256
},
"PD_Biped3D_Terrain_Forest_Hard-v0": 
{
	"config_file": "./args/genbiped3D/imitate_target_terr_biped3d_forest.txt",
	"time_limit": 256
},  
"PD_Biped3D_Terrain_Blocks_Hard-v0": 
{
	"config_file": "./args/genbiped3D/imitate_target_terr_biped3d_blocks.txt",
	"time_limit": 256
},
"PD_Biped3D_Terrain_Dyanmics_Obs_Hard-v0": 
{
	"config_file": "./args/genbiped3D/imitate_target_terr_biped3d_dynamics_obs.txt",
	"time_limit": 256
},
"comment__": "imitaion learning envs from DepLoco",
"PD_Biped3D_Imitate-Track-v0": 
{
	"config_file": "./args/genbiped3D/imitation/imitate_biped3d_track_state.txt",
	"time_limit": 256
},
"PD_Biped3D_Imitate-v0": 
{
	"config_file": "./args/genbiped3D/imitation/imitate_biped3d_phase.txt",
	"time_limit": 256
},
"PD_Biped3D_Imitate_NoPhase-v0": 
{
	"config_file": "./args/genbiped3D/imitation/imitate_biped3d_no_phase.txt",
	"time_limit": 256
},
"PD_Biped3D_Imitate_NoPhase_AxisAngle_v0": 
{
	"config_file": "./args/genbiped3D/imitation/imitate_biped3d_no_phase.txt",
	"time_limit": 256,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Use a different rotation representation for the policy learning state [quaternion|axisangle|euler]",
    	"poli_state_rot_type": "axisangle"
    }
},
"PD_Biped3D_Imitate_Symetric_NoPhase_AxisAngle_v0": 
{
	"config_file": "./args/genbiped3D/imitation/imitate_biped3d_symetric_no_phase.txt",
	"time_limit": 256,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Use a different rotation representation for the policy learning state [quaternion|axisangle|euler]",
    	"poli_state_rot_type": "axisangle"
    }
},
"PD_Biped3D_Imitate-Hills-v0": 
{
	"config_file": "./args/genbiped3D/imitation/imitate_biped3d_phase_hills3d.txt",
	"time_limit": 256
}, 
"PD_Biped3D_Imitate-Ramp-v0": 
{
	"config_file": "./args/genbiped3D/imitation/imitate_biped3d_phase_ramp3d.txt",
	"time_limit": 256
}, 
"PD_Biped3D_Imitate-Stairs-v0": 
{
	"config_file": "./args/genbiped3D/imitation/imitate_biped3d_phase_stairs3d.txt",
	"time_limit": 256
}, 
"PD_Biped3D_Imitate-Steps-v0": 
{
	"config_file": "./args/genbiped3D/imitation/imitate_biped3d_phase_steps3d.txt",
	"time_limit": 256
},        
"PD_Biped3D_FULL_Imitate-Steps-v0": 
{
	"config_file": "./args/genbiped3D/with_arms/llc_eval_args.txt",
	"time_limit": 256
},

"comment": "imitation envs from action space paper",
"Torque_Biped2D_LLC_Imitate_Flat-v0": 
{
	"config_file": "./args/imitation/torque/biped2d_llc_imitate_torque_flat_eval.txt",
	"time_limit": 256
},
"Torque_Dog2D_LLC_Imitate_Flat-v0": 
{
	"config_file": "./args/imitation/torque/dog2d_llc_imitate_torque_flat_eval.txt",
	"time_limit": 256
},
"Torque_Raptor2D_LLC_Imitate_Flat-v0": 
{
	"config_file": "./args/imitation/torque/raptor2d_llc_imitate_torque_flat_eval.txt",
	"time_limit": 256
},
        
"MTU_Biped2D_LLC_Imitate_Flat-v0": 
{
	"config_file": "./args/imitation/mtu/biped2d_llc_imitate_mtu_flat_eval.txt",
	"time_limit": 256
},
"MTU_Dog2D_LLC_Imitate_Flat-v0": 
{
	"config_file": "./args/imitation/mtu/dog2d_llc_imitate_mtu_flat_eval.txt",
	"time_limit": 256
},
"MTU_Raptor2D_LLC_Imitate_Flat-v0": 
{
	"config_file": "./args/imitation/mtu/raptor2d_llc_imitate_mtu_flat_eval.txt",
	"time_limit": 256
},        

"PD_Dog2D_LLC_Imitate_Flat-v0": 
{
	"config_file": "./args/imitation/pd/dog2d_imitate_eval_flat.txt",
	"time_limit": 256,
    "TerrainRL_Parameters":
    {    
            "comment__": "Use simple DeepLoco HLC reward function",
        "render_mode": "3d"
    }
},
"PD_Biped2D_LLC_Imitate_Flat-v0": 
{
	"config_file": "./args/imitation/pd/biped2d_imitate_eval_flat.txt",
	"time_limit": 256
},
"PD_Raptor2D_LLC_Imitate_Flat-v0": 
{
	"config_file": "./args/imitation/pd/raptor2d_imitate_eval_flat.txt",
	"time_limit": 256
},

"comment__": "These environments come from the terrainRL work",
"FSM_Biped2D_Terrain_Gaps-v0": 
{
	"config_file": "./args/terrainFSM/biped2d/biped2d_gaps.txt",
	"time_limit": 256,
	"control_return": true
},        
"FSM_Biped2D_Terrain_Cliffs-v0": 
{
	"config_file": "./args/terrainFSM/biped2d/biped2d_cliffs.txt",
	"time_limit": 256,
	"control_return": true
},    
"FSM_Biped2D_Terrain_Mixed-v0": 
{
	"config_file": "./args/terrainFSM/biped2d/biped2d_mixed.txt",
	"time_limit": 256,
	"control_return": true
},        
"FSM_Biped2D_Terrain_Slopes_Mixed-v0": 
{
	"config_file": "./args/terrainFSM/biped2d/biped2d_slopes_mixed.txt",
	"time_limit": 256,
	"control_return": true
},    
"FSM_Biped2D_Terrain_Slopes-v0": 
{
	"config_file": "./args/terrainFSM/biped2d/biped2d_slopes.txt",
	"time_limit": 256,
	"control_return": true
},        
"FSM_Biped2D_Terrain_Stairs_Rugged-v0": 
{
	"config_file": "./args/terrainFSM/biped2d/biped2d_stairs_rugged.txt",
	"time_limit": 256,
	"control_return": true
},        
"FSM_Biped2D_Terrain_Walls-v0": 
{
	"config_file": "./args/terrainFSM/biped2d/biped2d_walls.txt",
	"time_limit": 256,
	"control_return": true
},
"FSM_Biped2D_Terrain_Steps-v0": 
{
	"config_file": "./args/terrainFSM/biped2d/biped2d_steps.txt",
	"time_limit": 256,
	"control_return": true
},

"FSM_Dog2D_Terrain_Gaps-v0": 
{
	"config_file": "./args/terrainFSM/dog2d/gaps.txt",
	"time_limit": 256,
	"control_return": true
},        
"FSM_Dog2D_Terrain_Cliffs-v0": 
{
	"config_file": "./args/terrainFSM/dog2d/cliffs.txt",
	"time_limit": 256,
	"control_return": true
},    
"FSM_Dog2D_Terrain_Mixed-v0": 
{
	"config_file": "./args/terrainFSM/dog2d/mixed.txt",
	"time_limit": 256,
	"control_return": true
},        
"FSM_Dog2D_Terrain_Slopes_Mixed-v0": 
{
	"config_file": "./args/terrainFSM/dog2d/slopes_mixed.txt",
	"time_limit": 256,
	"control_return": true
},    
"FSM_Dog2D_Terrain_Slopes-v0": 
{
	"config_file": "./args/terrainFSM/dog2d/slopes.txt",
	"time_limit": 256,
	"control_return": true
},        
"FSM_Dog2D_Terrain_Stairs_Rugged-v0": 
{
	"config_file": "./args/terrainFSM/dog2d/stairs_rugged.txt",
	"time_limit": 256,
	"control_return": true
},        
"FSM_Dog2D_Terrain_Walls-v0": 
{
	"config_file": "./args/terrainFSM/dog2d/walls.txt",
	"time_limit": 256,
	"control_return": true
},
"FSM_Dog2D_Terrain_Steps-v0": 
{
	"config_file": "./args/terrainFSM/dog2d/steps.txt",
	"time_limit": 256,
	"control_return": true
},

"FSM_Raptor2D_Terrain_Gaps-v0": 
{
	"config_file": "./args/terrainFSM/raptor2d/gaps.txt",
	"time_limit": 256,
	"control_return": true
},        
"FSM_Raptor2D_Terrain_Cliffs-v0": 
{
	"config_file": "./args/terrainFSM/raptor2d/cliffs.txt",
	"time_limit": 256,
	"control_return": true
},    
"FSM_Raptor2D_Terrain_Mixed-v0": 
{
	"config_file": "./args/terrainFSM/raptor2d/mixed.txt",
	"time_limit": 256,
	"control_return": true
},        
"FSM_Raptor2D_Terrain_Slopes_Mixed-v0": 
{
	"config_file": "./args/terrainFSM/raptor2d/slopes_mixed.txt",
	"time_limit": 256,
	"control_return": true
},    
"FSM_Raptor2D_Terrain_Slopes-v0": 
{
	"config_file": "./args/terrainFSM/raptor2d/slopes.txt",
	"time_limit": 256,
	"control_return": true
},        
"FSM_Raptor2D_Terrain_Stairs_Rugged-v0": 
{
	"config_file": "./args/terrainFSM/raptor2d/stairs_rugged.txt",
	"time_limit": 256,
	"control_return": true
},        
"FSM_Raptor2D_Terrain_Walls-v0": 
{
	"config_file": "./args/terrainFSM/raptor2d/walls.txt",
	"time_limit": 256,
	"control_return": true
},
"FSM_Raptor2D_Terrain_Steps-v0": 
{
	"config_file": "./args/terrainFSM/raptor2d/steps.txt",
	"time_limit": 256,
	"control_return": true
},

"FSM_Hopper2D_Terrain_Gaps-v0": 
{
	"config_file": "./args/terrainFSM/hopper2d/gaps.txt",
	"time_limit": 256,
	"control_return": true
},        
"FSM_Hopper2D_Terrain_Cliffs-v0": 
{
	"config_file": "./args/terrainFSM/hopper2d/cliffs.txt",
	"time_limit": 256,
	"control_return": true
},    
"FSM_Hopper2D_Terrain_Mixed-v0": 
{
	"config_file": "./args/terrainFSM/hopper2d/mixed.txt",
	"time_limit": 256,
	"control_return": true
},        
"FSM_Hopper2D_Terrain_Slopes_Mixed-v0": 
{
	"config_file": "./args/terrainFSM/hopper2d/slopes_mixed.txt",
	"time_limit": 256,
	"control_return": true
},    
"FSM_Hopper2D_Terrain_Slopes-v0": 
{
	"config_file": "./args/terrainFSM/hopper2d/slopes.txt",
	"time_limit": 256,
	"control_return": true
},        
"FSM_Hopper2D_Terrain_Stairs_Rugged-v0": 
{
	"config_file": "./args/terrainFSM/hopper2d/stairs_rugged.txt",
	"time_limit": 256,
	"control_return": true
},        
"FSM_Hopper2D_Terrain_Walls-v0": 
{
	"config_file": "./args/terrainFSM/hopper2d/walls.txt",
	"time_limit": 256,
	"control_return": true
},
"FSM_Hopper2D_Terrain_Steps-v0": 
{
	"config_file": "./args/terrainFSM/hopper2d/steps.txt",
	"time_limit": 256,
	"control_return": true
},



"PD_Humanoid_3D_Symetric-v0": 
{
	"config_file": "./args/genbiped3D/humanoid3d_LLC_symetric_step_controller.txt",
	"time_limit": 256,
	"control_return": false
},


"Comment__": "Environments that include additional options for getting motion capture data",
"PD_Humanoid_3D_Symetric-Viz-v0": 
{
	"config_file": "./args/genbiped3D/humanoid3d_viz_symetric_step_controller.txt",
	"time_limit": 256,
	"control_return": false
},
"PD_Humanoid_3D_Symetric_Viz_v1": 
{
	"config_file": "./args/humanoid3D/humanoid3d_viz_symetric_step_controller.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
	"action_fps": 30,
	"timestep_subsampling": 4
},
"PD_Humanoid_2D_Symetric_Viz_v0": 
{
	"config_file": "./args/humanoid2D/humanoid2d_viz_controller.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 3,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [8, 8, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": false
},
"PD_Humanoid_2D_Viz_30fps_v0": 
{
	"config_file": "./args/humanoid2D/humanoid2d_viz_controller_30fps.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 3,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [8, 8, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": false
},
"PD_Humanoid_2D_Viz_Headless_30fps_v0": 
{
	"config_file": "./args/humanoid2D/humanoid2d_viz_controller_30fps.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 3,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [8, 8, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "false"
    }	
},
"PD_Humanoid_2D_Viz_30fps_SameStart_v0": 
{
	"config_file": "./args/humanoid2D/humanoid2d_viz_controller_30fps.txt",
	"time_limit": 15,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 3,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [8, 8, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "false"
    }	
},
"PD_Humanoid_2D_Symetric_Viz_Imitate_v0": 
{
	"config_file": "./args/humanoid2D/humanoid2d_viz_controller.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 3,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [8, 8, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": false
},
"PD_Humanoid_2D_Viz_Imitate_30FPS_v0": 
{
	"config_file": "./args/humanoid2D/humanoid2d_viz_controller_30fps.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 3,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [8, 8, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": false
},
"PD_Humanoid_2D_Viz_Imitate_30FPS_SameStart_v0": 
{
	"config_file": "./args/humanoid2D/humanoid2d_viz_controller_30fps.txt",
	"time_limit": 15,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 3,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [8, 8, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "false"
    }	
},
"PD_Humanoid_2D_Imitate_30FPS_v0": 
{
	"config_file": "./args/humanoid2D/humanoid2d_viz3D_controller_30fps.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": false,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [8, 8, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": false,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true"
    }	
},
"PD_HumanoidGRF_2D_Imitate_30FPS_v0": 
{
	"config_file": "./args/humanoid2D/humanoid2dGRF_viz3D_controller_30fps.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": false,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [8, 8, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": false,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true"
    }	
},
"PD_Humanoid_2D_Imitate_60FPS_Torque_v0": 
{
	"config_file": "./args/humanoid2D/humanoid2d_viz3D_controller_60fps_Torque.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": false,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 60,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [8, 8, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": false,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true"
    }	
},
"PD_Humanoid_2D_Imitate_15FPS_v0": 
{
	"config_file": "./args/humanoid2D/humanoid2d_viz3D_controller_15fps.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": false,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 15,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [8, 8, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": false,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true"
    }	
},
"PD_Humanoid_2D_Viz3D_Imitate_30FPS_v0": 
{
	"config_file": "./args/humanoid2D/humanoid2d_viz3D_controller_30fps.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 3,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [8, 8, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true"
    }	
},
"PD_Humanoid_2D_Viz3D_Imitate_30FPS_Channels_Last_v0": 
{
	"config_file": "./args/humanoid2D/humanoid2d_viz3D_controller_30fps.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 3,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [8, 8, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": true,
		"comment__": "Transpose image data, switches from channels_first to channels_last",
	"transpose_image_data": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true"
    }	
},
"PD_Humanoid_2D_Viz3D_128x128_Imitate_30FPS_v0": 
{
	"config_file": "./args/humanoid2D/humanoid2d_viz3D_controller_30fps.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 3,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true"
    }	
},
"PD_Humanoid_2D_Viz3D_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid2D/humanoid2d_viz3D_controller_30fps.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 3,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [8, 8, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true"
    }	
},
"PD_Humanoid_2D_Viz3D_64x64_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid2D/humanoid2d_viz3D_controller_30fps.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 3,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true"
    }	
},
"PD_Humanoid_2D_Viz3D_128x128_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid2D/humanoid2d_viz3D_controller_30fps.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 3,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true"
    }	
},
"PD_Humanoid_2D_Viz3D_128x128_1Sub_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid2D/humanoid2d_viz3D_controller_30fps.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true"
    }	
},
"PD_Humanoid_2D_Viz3D_64x64_1Sub_Imitate_30FPS_MultiModal_DualState_v0": 
{
	"config_file": "./args/humanoid2D/humanoid2d_viz3D_controller_30fps.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true"
    }	
},
"PD_Humanoid_2D_Viz3D_FixedStart_64x64_1Sub_Imitate_30FPS_MultiModal_DualState_v0": 
{
	"config_file": "./args/humanoid2D/humanoid2d_viz3D_controller_30fps.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "false"
    }	
},
"PD_Humanoid_GRF_2D_Viz3D_WithCamVel_FixedStart_64x64_1Sub_Imitate_30FPS_MultiModal_DualState_v0": 
{
	"config_file": "./args/humanoid2D/humanoid2d_viz3D_controller_30fps.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "false",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true	
},
"PD_Humanoid_2D_Viz3D_64x64_1Sub_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid2D/humanoid2d_viz3D_controller_30fps.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true"
    }	
},
"PD_Humanoid_2D_Viz3D_64x64_1Sub_WithCamVel_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid2D/humanoid2d_viz3D_controller_30fps.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true
},
"PD_Humanoid_2D_GRF_Viz3D_64x64_1Sub_WithCamVel_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid2D/humanoid2d_viz3D_controller_30fps.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true
},
"PD_Humanoid_2D_Viz3D_128x128_1Sub_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid2D/humanoid2d_viz3D_controller_30fps.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true"
    }	
},
"PD_Humanoid_2D_Viz3D_FixedStart_128x128_1Sub_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid2D/humanoid2d_viz3D_controller_30fps.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "false"
    }	
},
"PD_Humanoid_2D_Viz3D_64x64_1Sub_Imitate_30FPS_v0": 
{
	"config_file": "./args/humanoid2D/humanoid2d_viz3D_controller_30fps.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true"
    }	
},
"PD_Humanoid_2D_Viz3D_64x64_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid2D/humanoid2d_viz3D_controller_30fps.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 3,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true"
    }	
},
"PD_Humanoid_2D_Viz3D_64x64_Imitate_30FPS_DualVizState_v0": 
{
	"config_file": "./args/humanoid2D/humanoid2d_viz3D_controller_30fps.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 3,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": false,
	    "comment__": "Keep the viz state for the agent and the imitation character",
    "use_dual_viz_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true"
    }	
},
"PD_Humanoid_2D_Viz3D_64x64_Imitate_30FPS_DualPoseState_v0": 
{
	"config_file": "./args/humanoid2D/humanoid2d_viz3D_controller_30fps.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": false,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": false,
	    "comment__": "Keep the viz state for the agent and the imitation character",
    "use_dual_viz_state_representations": false,
    	    "comment__": "Keep the viz state for the agent and the imitation character",
    "use_dual_pose_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true"
    }	
},
"PD_Humanoid_2D_Viz3D_64x64_Imitate_30FPS_v0": 
{
	"config_file": "./args/humanoid2D/humanoid2d_viz3D_controller_30fps.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 3,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true"
    }	
},
"PD_Humanoid_2D_Viz3D_30FPS_v0": 
{
	"config_file": "./args/humanoid2D/humanoid2d_viz3D_controller_30fps.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": false,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [8, 8, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": false,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": false,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true"
    }	
},
"Headless_Viz3D_Test": 
{
	"config_file": "./args/humanoid2D/headless_viz3D_Test.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 3,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [0, 0, 800, 450],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [8, 8, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": false,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true"
    }	
},
"PD_Humanoid_2D_Viz_Imitate_30FPS_2_v0": 
{
	"comment__": "This env is designed to have a state that containts the visual state and the char state.",
	"config_file": "./args/humanoid2D/humanoid2d_viz_controller_30fps.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 3,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [8, 8, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": false,
        "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true
},
"PD_Humanoid_2D_Viz_Imitate_30FPS_SameStart_DualState_v0": 
{
	"comment__": "This env is designed to have a state that containts the visual state and the char state.",
	"config_file": "./args/humanoid2D/humanoid2d_viz_controller_30fps.txt",
	"time_limit": 30,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 3,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [8, 8, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": false,
        "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
    	"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "false"
    }	
},
"PD_Humanoid_3D_Viz3D_64x64_Imitate_30FPS_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_walk.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 3,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true"
    }	
},
"PD_Humanoid_3D_Viz3D_64x64_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_walk.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 3,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true"
    }	
},
"PD_Humanoid_3D_Viz3D_64x64_1Sub_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_walk.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true"
    }	
},
"PD_Humanoid_3D_Viz3D_128x128_1Sub_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_walk.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true"
    }	
},
"PD_Humanoid_3D_Viz3D_128x128_1Sub_Imitate_30FPS_DualPoseState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_walk.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": false,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": false,
	    "comment__": "Keep the viz state for the agent and the imitation character",
    "use_dual_viz_state_representations": false,
    	    "comment__": "Keep the viz state for the agent and the imitation character",
    "use_dual_pose_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true"
    }	
},
"PD_Humanoid_3D_Viz3D_FixedStart_128x128_1Sub_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_walk.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "false"
    }	
},
"PD_Humanoid_3D_Viz3D_FixedStart_128x128_1Sub_MultiModal_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_walk.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "false"
    }	
},
"PD_Humanoid_3D_Viz3D_FixedStart_64x64_1Sub_MultiModal_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_walk.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "false"
    }	
},
"PD_Humanoid_3D_Viz3D_64x64_1Sub_MultiModal_Imitate_30FPS_DualState_v0":
{
	"config_file": "./args/humanoid3D/humanoid3d1_walk.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true"
    }	
},
"PD_Humanoid_3D_TimeWarp_Viz3D_128x128_1Sub_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_walk_dynamic_timing.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true"
    }	
},
"PD_Humanoid_3D_TimeWarp_Run_Viz3D_128x128_1Sub_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run_dynamic_timing.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true"
    }	
},
"PD_Humanoid_3D_TimeWarp_BackFlip_Viz3D_128x128_1Sub_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_backflip_dynamic_timing.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true"
    }	
},
"PD_Humanoid_3D_TimeWarp_FrontFlip_Viz3D_128x128_1Sub_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_frontflip_dynamic_timing.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true"
    }	
},
"PD_Humanoid_3D_Viz3D_Run_128x128_1Sub_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true"
    }	
},
"PD_Humanoid_3D_Viz3D_FixedStart_Run_128x128_1Sub_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "false"
    }	
},
"PD_Humanoid_3D_Viz3D_FixedStart_Run_128x128_1Sub_MultiModal_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": false,
    	"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "false"
    }	
},
"PD_Humanoid_3D_Viz3D_Run_64x64_1Sub_MultiModal_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true"
    }	
},
"PD_Humanoid_3D_Viz3D_FixedStart_Run_64x64_1Sub_MultiModal_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "false"
    }	
},
"PD_Humanoid_3D_Viz3D_BackFlip_128x128_1Sub_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_backflip.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true"
    }	
},
"PD_Humanoid_3D_Viz3D_FixedStart_BackFlip_128x128_1Sub_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_backflip.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "false"
    }	
},
"PD_Humanoid_3D_Viz3D_FixedStart_BackFlip_128x128_1Sub_MultiModal_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_backflip.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "false"
    }	
},
"PD_Humanoid_3D_Viz3D_FixedStart_BackFlip_64x64_1Sub_MultiModal_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_backflip.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "false"
    }	
},
"PD_Humanoid_3D_Viz3D_BackFlip_64x64_1Sub_MultiModal_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_backflip.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true"
    }	
},
"PD_Humanoid_3D_Viz3D_FrontFlip_128x128_1Sub_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_frontflip.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true"
    }	
},
"PD_Humanoid_3D_Viz3D_FixedStart_FrontFlip_128x128_1Sub_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_frontflip.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "false"
    }	
},
"PD_Humanoid_3D_Viz3D_FixedStart_FrontFlip_128x128_1Sub_MultiModal_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_frontflip.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "false"
    }	
},
"PD_Humanoid_3D_Viz3D_FixedStart_FrontFlip_64x64_1Sub_MultiModal_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_frontflip.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "false"
    }	
},
"PD_Humanoid_3D_Viz3D_FrontFlip_64x64_1Sub_MultiModal_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_frontflip.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true"
    }	
},
"PD_Humanoid_3D_Viz3D_128x128_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_walk.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 3,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true"
    }	
},
"PD_Humanoid_GRF_Walk_3D_Viz3D_WithCamVel_128x128_1Sub_Imitate_30FPS_MultiModal_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_walk.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true	
},
"PD_Humanoid_GRF_3D_Run_Viz3D_WithCamVel_128x128_1Sub_Imitate_30FPS_MultiModal_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true	
},
"PD_Humanoid_GRF_3D_Run_Viz3D_WithCamVel_128x128_1Sub_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true	
},
"PD_Humanoid_GRF_3D_BackFlip_Viz3D_WithCamVel_128x128_1Sub_Imitate_30FPS_MultiModal_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_backflip.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true	
},
"PD_Humanoid_GRF_3D_FrontFlip_Viz3D_WithCamVel_128x128_1Sub_Imitate_30FPS_MultiModal_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_frontflip.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true	
},
"PD_Humanoid_GRF_Walk_3D_Viz3D_WithCamVel_FixedStart_128x128_1Sub_Imitate_30FPS_MultiModal_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_walk.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "false",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true	
},
"PD_Humanoid_GRF_3D_Run_Viz3D_WithCamVel_FixedStart_128x128_1Sub_Imitate_30FPS_MultiModal_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "false",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true	
},
"PD_Humanoid_GRF_3D_BackFlip_Viz3D_WithCamVel_FixedStart_128x128_1Sub_Imitate_30FPS_MultiModal_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_backflip.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "false",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true	
},
"PD_Humanoid_GRF_3D_BackFlip_Viz3D_WithCamVel_64x64_1Sub_Imitate_30FPS_DualState_v1": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run_zoom.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [365, 190, 64, 64],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [1, 1, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": false,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_backflip_wrap_wrist.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true	
},
"PD_Humanoid_GRF_3D_FrontFlip_Viz3D_WithCamVel_FixedStart_128x128_1Sub_Imitate_30FPS_MultiModal_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_frontflip.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "false",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true	
},
"PD_Humanoid_3D_BackFlip_Viz3D_128x128_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_backflip.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 3,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true"
    }	
},
"PD_Humanoid_3D_Run_Viz3D_128x128_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 3,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true"
    }	
},
"PD_Humanoid_3D_Viz3D_128x128_Imitate_30FPS_DualState_v0_Performance": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_walk.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 3,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true"
    }	
},
"PD_Humanoid_3D_WALK_Viz3D_64x64_Imitate_30FPS_DualVizState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_walk.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 3,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": false,
	    "comment__": "Keep the viz state for the agent and the imitation character",
    "use_dual_viz_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true"
    }	
},
"PD_Humanoid_3D_WALK_Imitate_30FPS_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_walk.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": false,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": false,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true"
    },
    	"comment__": "The type of simulation that determins the type of state vector",
    "sim_type": "3D"
},
"PD_Humanoid_3D_WALK_Imitate_30FPS_AxisAngle_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_walk.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": false,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": false,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Use a different rotation representation for the policy learning state [quaternion|axisangle|euler]",
    	"poli_state_rot_type": "axisangle"
    }	
},
"PD_Humanoid_3D_Symetric_PickUp_Viz_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d_viz_symetric_step_controller_pickup.txt",
	"time_limit": 512,
	"control_return": false
},
"PD_Humanoid_3D_Symetric_Walk_Viz_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d_viz_symetric_step_controller_walk.txt",
	"time_limit": 512,
	"control_return": false
},


"Comment__": "Environments that don't include phase info",
"PD_Humanoid_2D_Symetric-NoPhase-v0": 
{
	"config_file": "./args/genBiped2D/biped_full_imitate.txt",
	"time_limit": 256,
	"control_return": false
},
"PD_Humanoid_2D_Symetric_NoPhase_v1": 
{
	"config_file": "./args/humanoid2D/humanoid2d_viz_controller_30fps.txt",
	"time_limit": 256,
	"control_return": false
},
"PD_Humanoid_2D_Symetric_NoPhase_AxisAngle_v0": 
{
	"config_file": "./args/genBiped2D/biped_full_imitate.txt",
	"time_limit": 256,
	"control_return": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Use a different rotation representation for the policy learning state [quaternion|axisangle|euler]",
    	"poli_state_rot_type": "axisangle"
    }
},
"PD_Humanoid1_3D_WALK_Imitate_30FPS_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_walk.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": false,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": false,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true"
    }	
},
"PD_Humanoid1GRF_3D_WALK_Imitate_30FPS_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1GRF_walk.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": false,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": false,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true"
    }	
},
"PD_Humanoid1_3D_Symetric_Run_NoPhase_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_viz_symetric_step_controller_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": false,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [8, 8, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": false,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": false
},
"PD_Humanoid1_3D_Symetric_FrontFlip_NoPhase_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_frontflip.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": false,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [8, 8, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": false,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": false
},
"PD_Humanoid1_3D_BackFlip_NoPhase_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_frontflip.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": false,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [8, 8, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": false,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": false
},
"PD_Humanoid1_3D_BackFlip_NoPhase_v1": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_backflip.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": false,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [8, 8, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": false,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": false
},
"PD_Humanoid1GRF_3D_BackFlip_NoPhase_v1": 
{
	"config_file": "./args/humanoid3D/humanoid3d1GRF_backflip.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": false,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [8, 8, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": false,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": false
},
"PD_Humanoid1_3D_FrontFlip_NoPhase_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_frontflip.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": false,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [8, 8, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": false,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": false
},
"PD_Humanoid1GRF_3D_FrontFlip_NoPhase_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1GRF_frontflip.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": false,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [8, 8, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": false,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": false
},
"PD_Humanoid1_3D_Run_NoPhase_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": false,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [8, 8, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": false,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": false
},
"PD_Humanoid1_3D_Run_Phase_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": false,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [8, 8, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": false,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_phase"
    }
},
"PD_Humanoid1GRF_3D_Run_NoPhase_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": false,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [8, 8, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": false,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf"
    }
},
"PD_Humanoid_GRF_3D_Punch_Viz3D_1Sub_Imitate_30FPS_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": false,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": false,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": false,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_punch.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": false	
},
"PD_Humanoid_GRF_3D_BalanceBeam_Viz3D_1Sub_Imitate_30FPS_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": false,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": false,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": false,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_balance_beam_mirror.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": false	
},
"PD_Humanoid_GRF_3D_BaseballPitch_Viz3D_1Sub_Imitate_30FPS_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": false,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": false,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": false,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_baseball_pitch1.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": false	
},
"PD_Humanoid_GRF_3D_Cartwheel_Viz3D_1Sub_Imitate_30FPS_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": false,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": false,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": false,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_cartwheel_wrap.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": false	
},
"PD_Humanoid_GRF_3D_CartwheelMirror_Viz3D_1Sub_Imitate_30FPS_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": false,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": false,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": false,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_cartwheel_mirror_wrap.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": false	
},
"PD_Humanoid_GRF_3D_Crawl_Viz3D_1Sub_Imitate_30FPS_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": false,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": false,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": false,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_crawl_wrap.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": false	
},
"PD_Humanoid_GRF_3D_Walk_Viz3D_WithCamVel_128x128_1Sub_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_walk_wrap.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true	
},
"PD_Humanoid_GRF_3D_ZombieWalk_Viz3D_WithCamVel_128x128_1Sub_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_zombie_walk_wrap.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true	
},
"PD_Humanoid_GRF_3D_Punch_Viz3D_WithCamVel_128x128_1Sub_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_punch.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true	
},
"PD_Humanoid_GRF_3D_Jump_Viz3D_WithCamVel_128x128_1Sub_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_jump.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true	
},
"PD_Humanoid_GRF_3D_DanceB_Viz3D_WithCamVel_128x128_1Sub_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_dance_b.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true	
},
"PD_Humanoid_GRF_3D_DanceA_Viz3D_WithCamVel_128x128_1Sub_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_dance_a.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true	
},
"PD_Humanoid_GRF_3D_Helicopter_Viz3D_WithCamVel_128x128_1Sub_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_helicopter_wrap.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true	
},
"PD_Humanoid_GRF_3D_Kick_Viz3D_WithCamVel_128x128_1Sub_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_kick.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true	
},
"PD_Humanoid_2D_Viz3D_128x128_WithCamVel_1Sub_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid2D/humanoid2d_viz3D_controller_30fps.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true
},
"PD_Humanoid_2D_Viz3D_64x64_WithCamVel_1Sub_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid2D/humanoid2d_viz3D_controller_30fps.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true
},
"PD_Humanoid_2D_GRF_Viz3D_64x64_WithCamVel_1Sub_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid2D/humanoid2d_viz3D_controller_30fps.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true
},
"PD_Humanoid_2D_GRF_Viz3D_32x32_WithCamVel_1Sub_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid2D/humanoid2d_viz3D_controller_30fps.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [365, 190, 64, 64],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [1, 1, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": false,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Amount to change the caracter zoom focus.",
    	"camera_zoom": "-3.25"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true
},
"PD_Humanoid_2D_GRF_Viz3D_64x64_WithCamVel_1Sub_Imitate_30FPS_DualState_v1": 
{
	"config_file": "./args/humanoid2D/humanoid2d_viz3D_controller_30fps.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [365, 190, 64, 64],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [1, 1, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": false,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Amount to change the caracter zoom focus.",
    	"camera_zoom": "-3.25"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true
},
"PD_Humanoid_2D_GRF_Viz3D_64x64x1_WithCamVel_1Sub_Imitate_30FPS_DualState_v1": 
{
	"config_file": "./args/humanoid2D/humanoid2d_viz3D_controller_30fps.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [365, 190, 64, 64],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [1, 1, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Amount to change the caracter zoom focus.",
    	"camera_zoom": "-3.25"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true
},
"PD_Humanoid_2D_GRF_Viz3D_64x64_MultiModal_WithCamVel_1Sub_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid2D/humanoid2d_viz3D_controller_30fps.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true
},
"PD_Humanoid_2D_GRF_1Sub_Imitate_30FPS_DenseState_v0": 
{
	"config_file": "./args/humanoid2D/humanoid2d_viz3D_controller_30fps.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": false,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": false,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": false,
    	"comment__": "Keep the viz state for the agent and the imitation character",
    "use_dual_pose_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": false
},
"PD_Humanoid_GRF_3D_Punch_Viz3D_1Sub_Imitate_30FPS_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": false,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": false,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": false,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_punch.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": false	
},
"PD_Humanoid_GRF_3D_BalanceBeam_Viz3D_1Sub_Imitate_30FPS_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": false,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": false,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": false,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_balance_beam_mirror.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": false	
},
"PD_Humanoid_GRF_3D_BaseballPitch_Viz3D_1Sub_Imitate_30FPS_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": false,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": false,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": false,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_baseball_pitch1.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": false	
},
"PD_Humanoid_GRF_3D_Cartwheel_Viz3D_1Sub_Imitate_30FPS_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": false,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": false,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": false,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_cartwheel_wrap.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": false	
},
"PD_Humanoid_GRF_3D_CartwheelMirror_Viz3D_1Sub_Imitate_30FPS_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": false,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": false,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": false,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_cartwheel_mirror_wrap.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": false	
},
"PD_Humanoid_GRF_3D_Crawl_Viz3D_1Sub_Imitate_30FPS_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": false,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": false,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": false,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_crawl_wrap.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": false	
},
"PD_Humanoid_GRF_3D_Walk_Viz3D_1Sub_Imitate_30FPS_v0_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": false,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": false,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": false,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_walk_wrap.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": false	
},
"PD_Humanoid_GRF_3D_ZombieWalk_Viz3D_1Sub_Imitate_30FPS_v0_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": false,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": false,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": false,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_zombie_walk_wrap.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": false	
},
"PD_Humanoid_GRF_3D_Punch_Viz3D_1Sub_Imitate_30FPS_v0_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": false,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": false,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": false,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_punch.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": false	
},
"PD_Humanoid_GRF_3D_Jump_Viz3D_1Sub_Imitate_30FPS_v0_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": false,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": false,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": false,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_jump.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": false	
},
"PD_Humanoid_GRF_3D_DanceB_Viz3D_1Sub_Imitate_30FPS_v0_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": false,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": false,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": false,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_dance_b.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": false	
},
"PD_Humanoid_GRF_3D_DanceA_Viz3D_1Sub_Imitate_30FPS_v0_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": false,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": false,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": false,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_dance_a.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": false	
},
"PD_Humanoid_GRF_3D_Helicopter_Viz3D_1Sub_Imitate_30FPS_v0_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": false,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": false,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": false,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_helicopter_wrap.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": false	
},
"PD_Humanoid_GRF_3D_Kick_Viz3D_1Sub_Imitate_30FPS_v0_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": false,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [2, 2, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": false,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": false,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_kick.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": false	
},
"PD_Humanoid_GRF_3D_Walk_Viz3D_WithCamVel_64x64_1Sub_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_walk_wrap.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true	
},
"PD_Humanoid_GRF_3D_Walk_Viz3D_WithCamVel_64x64_1Sub_Imitate_30FPS_DualState_v1": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run_zoom.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [365, 190, 64, 64],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [1, 1, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": false,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_walk_wrap.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true	
},
"PD_Humanoid_GRF_3D_ZombieWalk_Viz3D_WithCamVel_64x64_1Sub_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_zombie_walk_wrap.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true	
},
"PD_Humanoid_GRF_3D_ZombieWalk_Viz3D_WithCamVel_64x64_1Sub_Imitate_30FPS_DualState_v1": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run_zoom.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [365, 190, 64, 64],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [1, 1, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": false,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_zombie_walk_wrap.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true	
},
"PD_Humanoid_GRF_3D_Punch_Viz3D_WithCamVel_64x64_1Sub_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_punch.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true	
},
"PD_Humanoid_GRF_3D_Jump_Viz3D_WithCamVel_64x64_1Sub_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_jump.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true	
},
"PD_Humanoid_GRF_3D_DanceB_Viz3D_WithCamVel_64x64_1Sub_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_dance_b.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true	
},
"PD_Humanoid_GRF_3D_DanceA_Viz3D_WithCamVel_64x64_1Sub_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_dance_a.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true	
},
"PD_Humanoid_GRF_3D_Helicopter_Viz3D_WithCamVel_64x64_1Sub_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_helicopter_wrap.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true	
},
"PD_Humanoid_GRF_3D_Kick_Viz3D_WithCamVel_64x64_1Sub_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_kick.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true	
},
"PD_Humanoid_GRF_3D_Run_Viz3D_WithCamVel_64x64_1Sub_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true	
},
"PD_Humanoid_GRF_3D_Run_Viz3D_WithCamVel_64x64_1Sub_Imitate_30FPS_DualState_v1": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run_zoom.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [365, 190, 64, 64],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [1, 1, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": false,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true	
},
"PD_Humanoid_GRF_3D_Walk_Viz3D_WithCamVel_64x64_1Sub_Imitate_30FPS_MultiModal_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_walk.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true	
},
"PD_Humanoid_GRF_3D_Kick_Viz3D_WithCamVel_64x64_1Sub_Imitate_30FPS_MultiModal_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_walk.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_kick.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true	
},
"PD_Humanoid_GRF_3D_Run_Viz3D_WithCamVel_64x64_1Sub_Imitate_30FPS_MultiModal_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true	
},
"PD_Humanoid_GRF_3D_DanceA_Viz3D_WithCamVel_64x64_1Sub_Imitate_30FPS_MultiModal_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_dance_a.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true	
},
"PD_Humanoid_GRF_3D_DanceB_Viz3D_WithCamVel_64x64_1Sub_Imitate_30FPS_MultiModal_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_dance_b.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true	
},
"PD_Humanoid_GRF_3D_Jump_Viz3D_WithCamVel_64x64_1Sub_Imitate_30FPS_MultiModal_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_jump.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true	
},
"PD_Humanoid_GRF_3D_Punch_Viz3D_WithCamVel_64x64_1Sub_Imitate_30FPS_MultiModal_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_punch.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true	
},
"PD_Humanoid_GRF_3D_ZombieWalk_Viz3D_WithCamVel_64x64_1Sub_Imitate_30FPS_MultiModal_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_zombie_walk_wrap.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true	
},
"PD_Humanoid_GRF_3D_Mixed_Viz3D_WithCamVel_64x64_1Sub_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d_mixed_controller.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_walk_wrap.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true	
},
"PD_Humanoid_3D_GRF_Walk_Imitate_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": false,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": false,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": false,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": false,
    	"comment__": "Keep the viz state for the agent and the imitation character",
    "use_dual_pose_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
   "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_walk_wrap.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": false
},
"PD_Humanoid_3D_GRF_Run_Imitate_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": false,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": false,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": false,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": false,
    	"comment__": "Keep the viz state for the agent and the imitation character",
    "use_dual_pose_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
   "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_run_mirror_wrists.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": false
},
"PD_Humanoid_3D_GRF_BackFlip_Imitate_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": false,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": false,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": false,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": false,
    	"comment__": "Keep the viz state for the agent and the imitation character",
    "use_dual_pose_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
   "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_backflip_wrap_wrist.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": false
},
"PD_Humanoid_3D_GRF_ZombieWalk_1Sub_Imitate_30FPS_DenseState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": false,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": false,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": false,
    	"comment__": "Keep the viz state for the agent and the imitation character",
    "use_dual_pose_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
   "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_zombie_walk_wrap.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": false
},
"PD_Humanoid_3D_GRF_Mixed_1Sub_Imitate_30FPS_DenseState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d_mixed_controller.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": false,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": false,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": false,
    	"comment__": "Keep the viz state for the agent and the imitation character",
    "use_dual_pose_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
   "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_walk_wrap.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": false
},
"PD_Humanoid_3D_GRF_Walk_1Sub_Imitate_30FPS_DenseState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": false,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": false,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": false,
    	"comment__": "Keep the viz state for the agent and the imitation character",
    "use_dual_pose_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
   "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_walk_wrap.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": false
},
"PD_Humanoid_3D_GRF_Jog_1Sub_Imitate_30FPS_DenseState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": false,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": false,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": false,
    	"comment__": "Keep the viz state for the agent and the imitation character",
    "use_dual_pose_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
   "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_jog_mirror.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": false
},
"PD_Humanoid_3D_GRF_Jab_1Sub_Imitate_30FPS_DenseState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": false,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": false,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": false,
    	"comment__": "Keep the viz state for the agent and the imitation character",
    "use_dual_pose_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
   "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_jab1.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": false
},
"PD_Humanoid_3D_GRF_BalanceBeam_1Sub_Imitate_30FPS_DenseState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": false,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": false,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": false,
    	"comment__": "Keep the viz state for the agent and the imitation character",
    "use_dual_pose_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
   "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_balance_beam_mirror.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": false
},
"PD_Humanoid_3D_GRF_Dance_A_1Sub_Imitate_30FPS_DenseState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": false,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": false,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": false,
    	"comment__": "Keep the viz state for the agent and the imitation character",
    "use_dual_pose_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
   "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_dance_a.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": false
},
"PD_Humanoid_3D_GRF_Dance_B_1Sub_Imitate_30FPS_DenseState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": false,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": false,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": false,
    	"comment__": "Keep the viz state for the agent and the imitation character",
    "use_dual_pose_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
   "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_dance_b.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": false
},
"PD_Humanoid_3D_GRF_Jump_1Sub_Imitate_30FPS_DenseState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": false,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": false,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": false,
    	"comment__": "Keep the viz state for the agent and the imitation character",
    "use_dual_pose_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
   "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_jump.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": false
},
"PD_Humanoid_3D_GRF_Run_1Sub_Imitate_30FPS_DenseState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": false,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": false,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": false,
    	"comment__": "Keep the viz state for the agent and the imitation character",
    "use_dual_pose_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
   "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_run_mirror_wrists.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": false
},
"PD_Humanoid_3D_GRF_Spin_1Sub_Imitate_30FPS_DenseState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": false,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": false,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": false,
    	"comment__": "Keep the viz state for the agent and the imitation character",
    "use_dual_pose_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
   "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_spin_wrap.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": false
},
"PD_Humanoid_GRF_3D_Mixed_Viz3D_1Sub_Imitate_30FPS_DenseState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d_mixed_controller.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": false,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": false,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": false,
    	"comment__": "Keep the viz state for the agent and the imitation character",
    "use_dual_pose_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
   "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_walk_wrap.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": false
},
"PD_Humanoid_GRF_3D_Mixed_Viz3D_1Sub_Imitate_30FPS_DenseState_v1": 
{
	"config_file": "./args/humanoid3D/humanoid3d_mixed_controller.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": false,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": false,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": false,
    	"comment__": "Keep the viz state for the agent and the imitation character",
    "use_dual_pose_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
   "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_walk_wrap.txt",
    		"comment__": "A new mix of imitation controllers that are more stable.",
    	"kin_ctrl_file": "data/controllers/humanoid3d/humanoid3d_mocap_mixed_stable.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": false
},
"PD_Humanoid_GRF_3D_Mixed_Half_Viz3D_1Sub_Imitate_30FPS_DenseState_v1": 
{
	"config_file": "./args/humanoid3D/humanoid3d_mixed_controller.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [32, 29, 64, 64],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
   "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Amount to change the caracter zoom focus.",
    	"camera_zoom": "0.30",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_run_mirror_wrists.txt",
    		"comment__": "A new mix of imitation controllers that are more stable.",
    	"kin_ctrl_file": "data/controllers/humanoid3d/humanoid3d_mocap_mixed_half.txt"
    },
        	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true,
    	"comment__": "Key Presses that change some of the rendered parts of the simulation",
    "rendering_key_presses": ["c", "k", "j"],
    "resize_window": [128,128],
    "resize_image": [1, 48, 48],
    "camera_zoom_noise": [-0.50, -0.1],
    "add_img_noise": false
},
"PD_Humanoid_GRF_3D_Mixed_Viz3D_WithCamVel_64x64_1Sub_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d_mixed_controller.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_walk_wrap.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true	
},
"PD_Humanoid_GRF_3D_Jog_Viz3D_WithCamVel_64x64_1Sub_Imitate_30FPS_DualState_v1": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run_zoom.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [365, 190, 64, 64],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [1, 1, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": false,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_jog_mirror.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true,
    	"comment__": "Include the camera velocity on the end of the state",
    "skip_reshape": false	
},
"PD_Humanoid_GRF_3D_Jog_Viz3D_WithCamVel_64x64_1Sub_Imitate_30FPS_DualState_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run_zoom.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [365, 190, 64, 64],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [1, 1, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_jog_mirror.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true,
    	"comment__": "Include the camera velocity on the end of the state",
    "skip_reshape": false	
},
"PD_Humanoid_GRF_3D_Jab_Viz3D_WithCamVel_64x64_1Sub_Imitate_30FPS_DualState_v1": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run_zoom.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [365, 190, 64, 64],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [1, 1, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": false,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_jab1.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true,
    	"comment__": "Include the camera velocity on the end of the state",
    "skip_reshape": false	
},
"PD_Humanoid_GRF_3D_BalanceBeam_Viz3D_WithCamVel_64x64_1Sub_Imitate_30FPS_DualState_v1": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run_zoom.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [365, 190, 64, 64],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [1, 1, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": false,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_balance_beam_mirror.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true,
    	"comment__": "Include the camera velocity on the end of the state",
    "skip_reshape": false	
},
"PD_Humanoid_GRF_3D_GetUp_Imitate_30FPS_v1": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": false,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [365, 190, 64, 64],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [1, 1, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": false,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": false,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": false,
    	"comment__": "Include both visual state and pose state for learning",
    "use_multimodal_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_getup_facedown.txt",
    		"comment__": "Specific character controller to use (in this case does not detect ground fall conteacts)",
    	"character_file": "data/characters/humanoid3d_colourful_contacts.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": false,
    	"comment__": "Include the camera velocity on the end of the state",
    "skip_reshape": false	
},
"PD_Humanoid_3D_GRF_Mixed_1Sub_Imitate_30FPS_ObsFlat_v0": 
{
	"config_file": "./args/humanoid3D/humanoid3d_mixed_controller.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": false,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [245, 75, 256, 256],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [4, 4, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": false,
		"comment__": "Enable headless rendering",
	"headless_render": false,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": false,
    	"comment__": "Keep the viz state for the agent and the imitation character",
    "use_dual_pose_state_representations": false,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
   "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_walk_wrap.txt",
    		"comment__": "The file that list all the tasks types to include",
    	"kin_ctrl_file": "data/controllers/humanoid3d/humanoid3d_mocap_mixed_small.txt"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": false,
    	"comment__": "Flatten the output observation",
    "flatten_observation": true
},
"PD_Humanoid_2D_GRF_Viz3D_16x16_1Sub_Imitate_30FPS_DualState_v1": 
{
	"config_file": "./args/humanoid2D/humanoid2d_viz3D_controller_30fps.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [393, 214, 16, 16],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [1, 1, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": false,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Amount to change the caracter zoom focus.",
    	"camera_zoom": "-10.25"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": false,
    	"comment__": "Key Presses that change some of the rendered parts of the simulation",
    "rendering_key_presses": ["c", "k", "j"]
},
"PD_Humanoid_2D_GRF_Viz3D_32x32_1Sub_Imitate_30FPS_DualState_v1": 
{
	"config_file": "./args/humanoid2D/humanoid2d_viz3D_controller_30fps.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [48, 45, 32, 32],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [1, 1, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Amount to change the caracter zoom focus.",
    	"camera_zoom": "-0.1"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true,
    	"comment__": "Key Presses that change some of the rendered parts of the simulation",
    "rendering_key_presses": ["c", "k", "j"],
    "resize_window": [128,128]
},
"PD_Humanoid_2D_GRF_Viz3D_48x48_1Sub_Imitate_30FPS_DualState_v1": 
{
	"config_file": "./args/humanoid2D/humanoid2d_viz3D_controller_30fps.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [32, 29, 64, 64],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [1, 1, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Amount to change the caracter zoom focus.",
    	"camera_zoom": "0.30"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true,
    	"comment__": "Key Presses that change some of the rendered parts of the simulation",
    "rendering_key_presses": ["c", "k", "j"],
    "resize_window": [128,128],
    "resize_image": [1, 48, 48],
    "camera_zoom_noise": [-0.50, -0.2],
    "add_img_noise": false
},
"PD_Humanoid_Morph_2D_GRF_Viz3D_48x48_1Sub_Imitate_30FPS_DualState_v1": 
{
	"config_file": "./args/humanoid2D/humanoid2d_viz3D_controller_30fps.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [32, 29, 64, 64],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [1, 1, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Amount to change the caracter zoom focus.",
    	"camera_zoom": "0.30",
    		"comment__": "Whether or not the initial morphology of the agent should be randomly sampled",
    	"enable_rand_morph_reset": "true"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true,
    	"comment__": "Key Presses that change some of the rendered parts of the simulation",
    "rendering_key_presses": ["c", "k", "j"],
    "resize_window": [128,128],
    "resize_image": [1, 48, 48],
    "camera_zoom_noise": [-0.50, -0.2],
    "add_img_noise": false
},
"PD_Humanoid_Morph_2D_GRF_Viz3D_TR_48x48_1Sub_Imitate_30FPS_DualState_v1": 
{
	"config_file": "./args/humanoid2D/humanoid2d_viz3D_controller_30fps.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [32, 29, 64, 64],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [1, 1, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Amount to change the caracter zoom focus.",
    	"camera_zoom": "0.30",
    		"comment__": "Whether or not the initial morphology of the agent should be randomly sampled",
    	"enable_rand_morph_reset": "true"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true,
    	"comment__": "Key Presses that change some of the rendered parts of the simulation",
    "rendering_key_presses": ["c", "k", "j"],
    "resize_window": [128,128],
    "resize_image": [1, 48, 48],
    "camera_zoom_noise": [-0.50, -0.1],
    "add_img_noise": false,
    "use_tiny_renderer": true
},
"PD_Humanoid_3D_GRF_Walk_Viz3D_48x48_1Sub_Imitate_30FPS_DualState_v1": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run_zoom.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [32, 29, 64, 64],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [1, 1, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_walk_wrap.txt",
    		"comment__": "Amount to change the caracter zoom focus.",
    	"camera_zoom": "0.30"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true,
    	"comment__": "Key Presses that change some of the rendered parts of the simulation",
    "rendering_key_presses": ["c", "k", "j"],
    "resize_window": [128,128],
    "resize_image": [1, 48, 48],
    "camera_zoom_noise": [-0.50, -0.2],
    "add_img_noise": false
},
"PD_Humanoid_3D_GRF_ZombieWalk_Viz3D_48x48_1Sub_Imitate_30FPS_DualState_v1": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run_zoom.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [32, 29, 64, 64],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [1, 1, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_zombie_walk_wrap.txt",
    		"comment__": "Amount to change the caracter zoom focus.",
    	"camera_zoom": "0.30"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true,
    	"comment__": "Key Presses that change some of the rendered parts of the simulation",
    "rendering_key_presses": ["c", "k", "j"],
    "resize_window": [128,128],
    "resize_image": [1, 48, 48],
    "camera_zoom_noise": [-0.50, -0.2],
    "add_img_noise": false
},
"PD_Humanoid_3D_GRF_Jog_Viz3D_48x48_1Sub_Imitate_30FPS_DualState_v1": 
{
	"config_file": "./args/humanoid3D/humanoid3d1_run_zoom.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [32, 29, 64, 64],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [1, 1, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Motion File to use for task",
    	"motion_file": "data/motions/humanoid3d_jog_mirror.txt",
    		"comment__": "Amount to change the caracter zoom focus.",
    	"camera_zoom": "0.30"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true,
    	"comment__": "Key Presses that change some of the rendered parts of the simulation",
    "rendering_key_presses": ["c", "k", "j"],
    "resize_window": [128,128],
    "resize_image": [1, 48, 48],
    "camera_zoom_noise": [-0.50, -0.2],
    "add_img_noise": false
},
"PD_Dog_2D_GRF_Viz3D_48x48_1Sub_Imitate_30FPS_DualState_v1": 
{
	"config_file": "./args/imitation/pd/dog2d_imitate_eval_flat.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [32, 29, 64, 64],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [1, 1, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Amount to change the caracter zoom focus.",
    	"camera_zoom": "0.30",
    		"comment__": "Use viz eval scenario",
    	"scenario": "imitate_viz_eval",
    	    "comment__": "Use simple DeepLoco HLC reward function",
        "render_mode": "3d"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true,
    	"comment__": "Key Presses that change some of the rendered parts of the simulation",
    "rendering_key_presses": ["c", "k", "j"],
    "resize_window": [128,128],
    "resize_image": [1, 48, 48],
    "camera_zoom_noise": [-0.50, -0.2],
    "add_img_noise": false
},
"PD_Dog_2D_GRF_Viz3D_48x48_Imitate_30FPS_DualState_PoseOnly_v1": 
{
	"config_file": "./args/imitation/pd/dog2d_imitate_eval_flat.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [32, 29, 64, 64],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [1, 1, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Amount to change the caracter zoom focus.",
    	"camera_zoom": "0.30",
    		"comment__": "Use viz eval scenario",
    	"scenario": "imitate_viz_eval",
    	    "comment__": "Use simple DeepLoco HLC reward function",
        "render_mode": "3d"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true,
    	"comment__": "Key Presses that change some of the rendered parts of the simulation",
    "rendering_key_presses": ["c", "k", "j"],
    "resize_window": [128,128],
    "resize_image": [1, 48, 48],
    "camera_zoom_noise": [-0.50, -0.2],
    "add_img_noise": false,
    "pose_only_state": true
},
"PD_Raptor_2D_GRF_Viz3D_48x48_1Sub_Imitate_30FPS_DualState_v1": 
{
	"config_file": "./args/imitation/pd/raptor2d_imitate_eval_flat.txt",
	"time_limit": 256,
	"control_return": false,
	"process_visual_data": true,
		"comment__": "Number of times the action is updated per second, fps",
	"action_fps": 30,
		"comment__": "Number of subsampled pose images taken between action updates",
	"timestep_subsampling": 1,
		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [32, 29, 64, 64],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [1, 1, 1],
		"comment__": "Whether or not to convert the image to grayscale",
	"convert_to_greyscale": true,
		"comment__" : "Whether or not to collect imitation visual data as well (skip for efficiency)",
	"also_imitation_visual_data": true,
		"comment__": "Enable headless rendering",
	"headless_render": true,
	    "comment__": "Mix different state discription types, used for debugging visual imitation learning",
    "use_dual_state_representations": true,
		"comment__": "Parameters that are for the TerrainRL simulation directly",
    "TerrainRL_Parameters":
    {	
    		"comment__": "Whether or not the initial pose for the character should be sampled from the mocap data",
    	"enable_rand_state_reset": "true",
    		"comment__": "Type of controller to use, controls the environment state",
    	"char_ctrl": "ct_pd_grf",
    		"comment__": "Amount to change the caracter zoom focus.",
    	"camera_zoom": "0.30",
    		"comment__": "Use viz eval scenario",
    	"scenario": "imitate_viz_eval",
    	    "comment__": "Use simple DeepLoco HLC reward function",
        "render_mode": "3d"
    },
    	"comment__": "Include the camera velocity on the end of the state",
    "append_camera_velocity_state": true,
    	"comment__": "Key Presses that change some of the rendered parts of the simulation",
    "rendering_key_presses": ["c", "k", "j"],
    "resize_window": [128,128],
    "resize_image": [1, 48, 48],
    "camera_zoom_noise": [-0.50, -0.2],
    "add_img_noise": false
},
"PD_Biped3D_Cliff_v0": 
{
	"config_file": "./args/humanoid3D/LLC_waypoint_symetric_step_controller.txt",
	"time_limit": 512,
	"TerrainRL_Parameters":
    {	
    	"scenario": "imitate_viz_eval",
    		"comment__": "Specific controller type to use",
    	"char_ctrl": "ct_pd",
    	"InitialPaddingWidth": "0.7",
    	"terrain_file": "data/terrain/cliff_humanoid.txt"
    },
    	"comment__": "Key Presses that change some of the rendered parts of the simulation",
    "rendering_key_presses": ["c", "k", "j"],
    		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [365, 190, 64, 64],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [1, 1, 1]
	
},
"PD_Biped3D_Treadmill_v0": 
{
	"config_file": "./args/humanoid3D/LLC_waypoint_symetric_step_controller.txt",
	"time_limit": 256,
	"TerrainRL_Parameters":
    {	
    	"scenario": "imitate_viz_eval",
    		"comment__": "Specific controller type to use",
    	"char_ctrl": "ct_pd",
    		"comment__": "Use simple DeepLoco HLC reward function",
    	"terrain_file": "data/terrain/threadmill.txt"
    },
    	"comment__": "Key Presses that change some of the rendered parts of the simulation",
    "rendering_key_presses": ["c", "k", "j"],
    		"comment__": "Area that will be clipped from the rendering using glReadPixels [x, y, width, height]",
	"image_clipping_area": [365, 190, 64, 64],
		"comment__": "Amount of downsampling that will be done to the image",
	"downsample_image": [1, 1, 1]
}

}
